{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gzguevara/amex_kaggle/blob/master/Train_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrb7n4eJF27U"
      },
      "source": [
        "# Import Drive and XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Han3-fXyTN6j",
        "outputId": "7256800b-64b9-49a7-97d1-3a45052be028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found existing installation: xgboost 0.90\n",
            "Uninstalling xgboost-0.90:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/xgboost-0.90.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/xgboost/*\n",
            "    /usr/local/xgboost/libxgboost.so\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled xgboost-0.90\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 192.9 MB 53 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n",
            "Installing collected packages: xgboost\n",
            "Successfully installed xgboost-1.6.1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip uninstall xgboost\n",
        "!pip install xgboost\n",
        "\n",
        "#!pip install import_ipynb\n",
        "#import import_ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_Lz0gyTjumy"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7Fj6oq8fQhsm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy  as np  \n",
        "import cupy\n",
        "# for cupu memory managmet\n",
        "mempool        = cupy.get_default_memory_pool()\n",
        "pinned_mempool = cupy.get_default_pinned_memory_pool()\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import sys\n",
        "from importlib import reload #test = reload(test)\n",
        "\n",
        "import matplotlib.pyplot as plt, gc, os\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "# Paths\n",
        "train_dir   = '/content/drive/MyDrive/KaggleAMEX/Data/train.parquet'\n",
        "impor_dir   = '/content/drive/MyDrive/KaggleAMEX/Importance'\n",
        "targets_dir = '/content/drive/MyDrive/KaggleAMEX/Data/train_labels.csv'\n",
        "\n",
        "#Parameters\n",
        "SEED  = 42\n",
        "FOLDS = 5\n",
        "\n",
        "#Get numerical and catecorical columns \n",
        "\n",
        "cat_features = ['B_30', 'B_38', 'D_117', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68', 'B_33', 'D_92', 'D_103', 'R_27', 'D_114', 'D_116', 'D_129', 'D_139', 'D_140', 'D_143', 'B_8', 'D_51', 'D_54', 'D_65', 'B_16', 'B_22', 'D_72', 'D_78', 'D_79', 'R_9', 'D_82', 'D_107', 'D_122', 'D_125']\n",
        "bin_features = ['R_2', 'S_6', 'R_4', 'R_15', 'S_18', 'D_86', 'D_87', 'B_31', 'R_19', 'B_32', 'S_20', 'R_21', 'R_22', 'R_23', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'D_127', 'R_28', 'D_109', 'D_120', 'D_135', 'D_137', 'R_7', 'R_12', 'R_14', 'D_112']\n",
        "num_features = ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'D_50', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'B_17', 'B_18', 'B_19', 'B_20', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'D_70', 'D_71', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'D_77', 'B_25', 'B_26', 'R_8', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'S_17', 'B_28', 'R_13', 'D_83', 'D_84', 'R_16', 'B_29', 'R_17', 'R_18', 'D_88', 'S_19', 'R_20', 'D_89', 'D_91', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_104', 'D_105', 'D_106', 'B_36', 'B_37', 'R_26', 'D_108', 'D_110', 'D_111', 'B_39', 'B_40', 'S_27', 'D_113', 'D_115', 'D_118', 'D_119', 'D_121', 'D_123', 'D_124', 'D_128', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'D_134', 'D_136', 'D_138', 'D_141', 'D_142', 'D_144', 'D_145']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juv-r73KS3a_"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "crYzLkbkPWsP"
      },
      "outputs": [],
      "source": [
        "def process_and_feature_engineer(cus_range, obs):\n",
        "\n",
        "    # Get customer frequency\n",
        "    frequency = pd.read_csv('/content/drive/MyDrive/KaggleAMEX/Data/train/frequency.csv', index_col=0)\n",
        "    customers = frequency.loc[frequency.frequency.isin(cus_range)].index.values\n",
        "    \n",
        "    # num - mean, std, min, max, last\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/base_variables.parquet'\n",
        "    df  = pd.read_parquet(dir)\n",
        "    df  = df.loc[customers]\n",
        "    print('Done base', df.shape)\n",
        "\n",
        "    # Add woe categorial\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/base_variables_cat_woe.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done woe categorial', df.shape)\n",
        "\n",
        "    # categorial & binary state changes\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/state_changes.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done state changes', df.shape)\n",
        "\n",
        "    # non linear numerical\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/nonlinear.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done non linear', df.shape)\n",
        "    \n",
        "    # p_b_s_r_d variables corr and cat/bin sum \n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/p_b_s_r_d.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done p_b_s_r_d variables', df.shape)\n",
        "    \n",
        "    # count na & not na values\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/mean_na.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done count na variables', df.shape)\n",
        "\n",
        "    # First & second difference\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/diffs.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done diffs variables', df.shape)\n",
        "\n",
        "    # Sum woe numerical\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/num_woe_sum.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done sum woe', df.shape)\n",
        "\n",
        "    # Advanced\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/advanced.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done advanced features', df.shape)\n",
        "    \n",
        "    # Add targets\n",
        "    targets      = pd.read_csv(targets_dir, usecols = ['target']).astype('int8')\n",
        "    df['target'] = targets.loc[customers]\n",
        "\n",
        "    # Drop na columns\n",
        "    to_drop = [x for x in df.columns if len(df[x].unique())==1]\n",
        "    df.drop(to_drop, axis=1, inplace=True)\n",
        "    print(f'Droped {len(to_drop)} features. New Shape:', df.shape)\n",
        "\n",
        "    # Reset index\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Downsample majority class\n",
        "    df['freq']  = frequency.frequency\n",
        "    df_majority = df.loc[df.target == 0]\n",
        "    df_minority = df.loc[df.target == 1]\n",
        "\n",
        "    df_majority = resample(df_majority, \n",
        "                          replace      = False,    \n",
        "                          n_samples    = df_minority.shape[0], # int(obs/2), # \n",
        "                          random_state = SEED,\n",
        "                          stratify     = df_minority.freq)\n",
        "    '''\n",
        "    df_minority = resample(df_minority, \n",
        "                          replace      = False,    \n",
        "                          n_samples    = int(obs/2), \n",
        "                          random_state = SEED,\n",
        "                          stratify     = df_minority.freq)\n",
        "    '''\n",
        "    df = pd.concat([df_majority, df_minority])\n",
        "    df = df.sample(frac=1, random_state=SEED)\n",
        "    df.drop('freq', axis=1, inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    print('Downsampled to', df.shape)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KOqHWr4Qhso"
      },
      "source": [
        "# Read & Transform Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNhMjOowI7P2",
        "outputId": "53bf1af1-8696-433c-f410-bfb6392ccc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done base (458913, 637)\n",
            "Done woe categorial (458913, 669)\n",
            "Done state changes (458913, 730)\n",
            "Done non linear (458913, 912)\n",
            "Done p_b_s_r_d variables (458913, 918)\n",
            "Done count na variables (458913, 1294)\n",
            "Done diffs variables (458913, 1550)\n",
            "Done sum woe (458913, 1677)\n",
            "Done advanced features (458913, 1922)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Droped 132 features. New Shape: (458913, 1791)\n",
            "Downsampled to (237656, 1791)\n"
          ]
        }
      ],
      "source": [
        "train = process_and_feature_engineer(cus_range=list(range(1,14)), obs=2500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqSKKYASQhsv"
      },
      "source": [
        "# Extreme Gradient Boost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rX6N4YTs4-U"
      },
      "source": [
        "### Custom metric & permutation importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MeDwbg2Os4tb"
      },
      "outputs": [],
      "source": [
        "# This is the metric given by rules\n",
        "def amex_metric_mod(y_true, y_pred):\n",
        "\n",
        "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz        = cum_pos_found / total_pos\n",
        "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
        "\n",
        "\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
        "    \n",
        "\n",
        "# Metric for XGB\n",
        "def xgboost_amex_metric_mod(predt: np.ndarray, dtrain: xgb.DMatrix):\n",
        "    y = dtrain.get_label()\n",
        "    return 'AMEXcustom', 1-amex_metric_mod(y, predt)\n",
        "\n",
        "def permutation_importance(train, valid_idx, features, model, kag_mets):\n",
        "\n",
        "    # Permutation importance\n",
        "    x_test  = train.loc[valid_idx, train.columns[:-1]]\n",
        "    y_test  = train.loc[valid_idx, 'target']\n",
        "    metrics = []\n",
        "\n",
        "    for column, feature in enumerate(features):\n",
        "\n",
        "          #Save original feature\n",
        "          original_feature = x_test[feature].copy()\n",
        "          metric = []\n",
        "\n",
        "          for i in range(1):\n",
        "\n",
        "              # Shuffel\n",
        "              x_test[feature] = np.random.permutation(original_feature)\n",
        "\n",
        "              #Build DMatrix\n",
        "              dvalid = xgb.DMatrix(data=cupy.array(x_test))\n",
        "              \n",
        "              #Predict\n",
        "              preds  = model.predict(dvalid, iteration_range=(0, model.best_iteration + 1))\n",
        "              metric.append(kag_mets - amex_metric_mod(y_test, preds))\n",
        "\n",
        "          metrics.append(np.mean(metric))\n",
        "\n",
        "          #Rebuild data\n",
        "          x_test[feature] = original_feature\n",
        "    \n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP8vVxNQs3CR"
      },
      "source": [
        "### Get grid & feature order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ4A0OlhDfdw",
        "outputId": "1741f9f3-3283-46f5-9425-0927a0f97faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 different Models. \n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "learning_rate     = [0.04]          \n",
        "gamma             = [0]\n",
        "\n",
        "max_depth         = [4]                     \n",
        "max_leaves        = [0]             \n",
        "max_bin           = [256]               \n",
        "\n",
        "subsample         = [0.8]   \n",
        "sampling_method   = ['gradient_based'] #'gradient_based', \n",
        "\n",
        "colsample_bytree  = [0.1]             \n",
        "colsample_bylevel = [1]             \n",
        "colsample_bynode  = [1]             \n",
        "                   \n",
        "alpha             = [1]             \n",
        "lambda_           = [3]             \n",
        "\n",
        "min_child_weight  = [2]    \n",
        "scale_pos_weight  = [1]\n",
        "\n",
        "grow_policy       = ['depthwise']\n",
        "\n",
        "tree_method       = ['gpu_hist']        \n",
        "objective         = ['binary:logistic']\n",
        "predictor         = ['gpu_predictor']\n",
        "seed              = [SEED]\n",
        "\n",
        "booster           = ['dart']\n",
        "sample_type       = ['uniform']\n",
        "normalize_type    = ['tree']\n",
        "rate_drop         = [0.2]\n",
        "skip_drop         = [0.5]\n",
        "\n",
        "# Get Grids for xgb\n",
        "hyper_parms = ['grow_policy', 'learning_rate', 'gamma', 'max_depth', 'min_child_weight', 'subsample', 'sampling_method', 'colsample_bytree', 'colsample_bylevel', 'colsample_bynode', 'lambda', 'alpha', 'scale_pos_weight', 'max_leaves', 'max_bin', 'tree_method', 'objective', 'predictor', 'seed', 'booster', 'sample_type', 'normalize_type', 'rate_drop', 'skip_drop']\n",
        "variants    = list(itertools.product(grow_policy, learning_rate, gamma, max_depth, min_child_weight, subsample, sampling_method, colsample_bytree, colsample_bylevel, colsample_bynode, lambda_, alpha, scale_pos_weight, max_leaves, max_bin, tree_method, objective, predictor, seed, booster, sample_type, normalize_type, rate_drop, skip_drop))\n",
        "xgb_grid    = [dict(zip(hyper_parms, variant)) for variant in variants]\n",
        "random.shuffle(xgb_grid)\n",
        "xgb_grid = xgb_grid[:200]\n",
        "\n",
        "print(f'There are {len(xgb_grid)} different Models.', '\\n', '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permu_copy = premu_imp.copy()"
      ],
      "metadata": {
        "id": "m1wVQ-z6mEka"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp = premu_imp.loc[premu_imp.med > 0].copy()"
      ],
      "metadata": {
        "id": "46JAyWi-6jLT"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[premu_imp.index.to_list() + ['target']]"
      ],
      "metadata": {
        "id": "61cqAz0V6q5E"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp['weight'] = [0] * premu_imp.shape[0]"
      ],
      "metadata": {
        "id": "MUJTKPhG9kNc"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp['weight'] = premu_imp['med']"
      ],
      "metadata": {
        "id": "9fq50y0Z9rI4"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp['weight'] = premu_imp.med / premu_imp.med.sum()"
      ],
      "metadata": {
        "id": "_1DNf2_c_zFi"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get orders\n",
        "orders  = []\n",
        "\n",
        "weights = premu_imp.weight.to_list()  # [1/len(train.columns[:-1])] * len(train.columns[:-1])  # \n",
        "cols    = train.columns[:-1].to_list()     # train.columns[:-1].to_list() \n",
        "\n",
        "join = list(zip(cols, weights))\n",
        "\n",
        "for order in range(3):\n",
        "\n",
        "  random.shuffle(join)\n",
        "  orders.append(join.copy())\n",
        "\n",
        "print(f'There are {len(orders)} different order.', '\\n', '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLr8h5TPXREt",
        "outputId": "2ed3303f-a2ec-49ec-8fbd-db4214318d79"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3 different order. \n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search & Permutation Importance"
      ],
      "metadata": {
        "id": "P9_RnCF-1wvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMAdr01JQhsw",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca40f81f-dbef-4a57-fb39-402a2728878d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########### Order 0 Model 0 Fold 0 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.66953\tvalid-AMEXcustom:0.36770\n",
            "[500]\tvalid-logloss:0.26034\tvalid-AMEXcustom:0.28242\n",
            "[1000]\tvalid-logloss:0.25466\tvalid-AMEXcustom:0.27927\n",
            "[1500]\tvalid-logloss:0.25278\tvalid-AMEXcustom:0.27572\n"
          ]
        }
      ],
      "source": [
        "# Out-of-fold predictions & permutation  importances\n",
        "oof_cols  = [f'fold_{i}' for i in range(FOLDS)] + ['avg', 'oof']\n",
        "oof       = pd.DataFrame(columns = oof_cols)\n",
        "premu_imp = pd.DataFrame()\n",
        "\n",
        "# Get feature order & weights\n",
        "for order_num, order in enumerate([orders[0]]):\n",
        "\n",
        "      weights     = [x[1] for x in order]\n",
        "      features    = [x[0] for x in order]\n",
        "      train       = train[features + ['target']]\n",
        "      premu_order = pd.DataFrame(index=train.columns[:-1])\n",
        "\n",
        "      # Start grid search\n",
        "      for model_num, xgb_parms in enumerate(xgb_grid):\n",
        "\n",
        "            kag_mets  = []\n",
        "            oof_model = pd.DataFrame()\n",
        "\n",
        "            # Start cross validation\n",
        "            skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=11)\n",
        "            for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
        "                \n",
        "                  print(f'########### Order {order_num} Model {model_num} Fold {fold} #############')\n",
        "                  print('##################################################')\n",
        "                  \n",
        "                  # Train and valid set for given fold       \n",
        "                  x_valid = cupy.array(train.loc[valid_idx, train.columns[:-1]])\n",
        "                  y_valid = cupy.array(train.loc[valid_idx, 'target'])\n",
        "                  dvalid  = xgb.DMatrix(data=x_valid, label=y_valid)\n",
        "                  \n",
        "                  x_train = cupy.array(train.loc[train_idx, train.columns[:-1]])\n",
        "                  y_train = cupy.array(train.loc[train_idx, 'target'])\n",
        "                  dtrain  = xgb.DeviceQuantileDMatrix(data=x_train, label=y_train, feature_weights=weights)\n",
        "\n",
        "                  # Train model\n",
        "                  model = xgb.train(params                = xgb_parms,\n",
        "                                    dtrain                = dtrain,\n",
        "                                    evals                 = [(dvalid,'valid')],\n",
        "                                    custom_metric         = xgboost_amex_metric_mod,\n",
        "                                    num_boost_round       = 10000,\n",
        "                                    early_stopping_rounds = 300,\n",
        "                                    verbose_eval          = 500)\n",
        "                \n",
        "                  # Save model\n",
        "                  model_dir = '/content/drive/MyDrive/KaggleAMEX/Models/freq_3'\n",
        "                  model.save_model(f'{model_dir}/avg_fold_{fold}.xgb')\n",
        "                  #model.save_model(f'{model_dir}/oof_fold_{fold}.xgb')\n",
        "                          \n",
        "                  # Validation - Infer out-of-fold\n",
        "                  preds     = model.predict(dvalid, iteration_range=(0, model.best_iteration + 1))\n",
        "                  df        = pd.DataFrame(data=preds, index=valid_idx, columns=['oof'])\n",
        "                  oof_model = pd.concat([oof_model, df], axis = 0)\n",
        "\n",
        "                  # Kaggle metric\n",
        "                  kag_mets.append(amex_metric_mod(y_valid.get(), preds))\n",
        "                  curr_best = np.max([oof[f'fold_{fold}'].max(), kag_mets[-1]])\n",
        "                  print(f'Metric = {kag_mets[-1]}, Best = {curr_best}', '\\n')\n",
        "                  \n",
        "                  # Skip if no significant improvment\n",
        "                  #if kag_mets[-1] + 0.02 < curr_best: break\n",
        "                  \n",
        "                  # Permutation importance\n",
        "                  #premu_order[f'order_{order_num}_grid_{model_num}_fold_{fold}'] = permutation_importance(train, valid_idx, train.columns[:-1], model, kag_mets[-1])\n",
        "                  \n",
        "                  # Clean RAM & GPU RAM\n",
        "                  del y_train, x_train, y_valid, x_valid, dtrain, dvalid, train_idx, valid_idx\n",
        "                  mempool.free_all_blocks(), pinned_mempool.free_all_blocks(), gc.collect()\n",
        "                    \n",
        "            # Skip if fold not compleat\n",
        "            if len(kag_mets) != 5: continue\n",
        "          \n",
        "            # Metrics\n",
        "            kag_mets.append(np.mean(kag_mets))\n",
        "            kag_mets.append(amex_metric_mod(train.target.values, oof_model.sort_index().oof.values))\n",
        "            oof.loc[f'order_{order_num}_model_{model_num}'] = kag_mets\n",
        "            print(f'avg: {kag_mets[-2]}, Max: {oof.avg.max()}')\n",
        "            print(f'oof: {kag_mets[-1]}, Max: {oof.oof.max()}', '\\n', '\\n', '\\n')\n",
        "            \n",
        "      premu_imp = pd.concat([premu_order,premu_imp], axis=1)\n",
        "\n",
        "# Average over folds\n",
        "premu_imp['avg'] = premu_imp.mean(axis=1)\n",
        "premu_imp.sort_values('avg', ascending=False, inplace=True)\n",
        "oof.sort_values('oof', ascending=False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oof.sort_values('avg', ascending=False) # order_0_model_104 0.726660 order_0_model_187 0.723227"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "J__jCVDPz_Ze",
        "outputId": "191dbfdd-5f4d-43f4-e56e-8cc3ae06951b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    fold_0    fold_1    fold_2    fold_3    fold_4       avg  \\\n",
              "order_0_model_7   0.726176  0.725421  0.728362  0.728087  0.722362  0.726082   \n",
              "order_0_model_3   0.727365  0.723443  0.726643  0.726396  0.725356  0.725841   \n",
              "order_0_model_1   0.725295  0.726182  0.726804  0.726465  0.724335  0.725816   \n",
              "order_0_model_15  0.726626  0.724385  0.725337  0.727326  0.724785  0.725692   \n",
              "order_0_model_2   0.726026  0.725339  0.726025  0.727015  0.723650  0.725611   \n",
              "order_0_model_10  0.723002  0.724125  0.726679  0.727765  0.724918  0.725298   \n",
              "order_0_model_13  0.726188  0.725868  0.724457  0.726574  0.723165  0.725250   \n",
              "order_0_model_14  0.726635  0.723331  0.726652  0.726307  0.722684  0.725122   \n",
              "order_0_model_5   0.724562  0.725678  0.726044  0.726695  0.720412  0.724678   \n",
              "order_0_model_6   0.725134  0.723587  0.724750  0.724656  0.722338  0.724093   \n",
              "order_0_model_11  0.724360  0.721621  0.724134  0.725047  0.723051  0.723642   \n",
              "order_0_model_8   0.726310  0.721494  0.722096  0.723774  0.722089  0.723153   \n",
              "order_0_model_0   0.721843  0.718059  0.720634  0.720957  0.718352  0.719969   \n",
              "order_0_model_12  0.715258  0.715772  0.716382  0.719162  0.716568  0.716628   \n",
              "order_0_model_4   0.719038  0.714977  0.714792  0.719312  0.714353  0.716494   \n",
              "order_0_model_9   0.714727  0.714949  0.719028  0.719080  0.714218  0.716401   \n",
              "\n",
              "                       oof  \n",
              "order_0_model_7   0.725550  \n",
              "order_0_model_3   0.725218  \n",
              "order_0_model_1   0.725372  \n",
              "order_0_model_15  0.724709  \n",
              "order_0_model_2   0.724312  \n",
              "order_0_model_10  0.724643  \n",
              "order_0_model_13  0.724821  \n",
              "order_0_model_14  0.724677  \n",
              "order_0_model_5   0.724052  \n",
              "order_0_model_6   0.723838  \n",
              "order_0_model_11  0.723001  \n",
              "order_0_model_8   0.722150  \n",
              "order_0_model_0   0.718930  \n",
              "order_0_model_12  0.716017  \n",
              "order_0_model_4   0.715829  \n",
              "order_0_model_9   0.716170  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a268d01-6072-4fff-8385-ee0c2de1ae74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold_0</th>\n",
              "      <th>fold_1</th>\n",
              "      <th>fold_2</th>\n",
              "      <th>fold_3</th>\n",
              "      <th>fold_4</th>\n",
              "      <th>avg</th>\n",
              "      <th>oof</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>order_0_model_7</th>\n",
              "      <td>0.726176</td>\n",
              "      <td>0.725421</td>\n",
              "      <td>0.728362</td>\n",
              "      <td>0.728087</td>\n",
              "      <td>0.722362</td>\n",
              "      <td>0.726082</td>\n",
              "      <td>0.725550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_3</th>\n",
              "      <td>0.727365</td>\n",
              "      <td>0.723443</td>\n",
              "      <td>0.726643</td>\n",
              "      <td>0.726396</td>\n",
              "      <td>0.725356</td>\n",
              "      <td>0.725841</td>\n",
              "      <td>0.725218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_1</th>\n",
              "      <td>0.725295</td>\n",
              "      <td>0.726182</td>\n",
              "      <td>0.726804</td>\n",
              "      <td>0.726465</td>\n",
              "      <td>0.724335</td>\n",
              "      <td>0.725816</td>\n",
              "      <td>0.725372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_15</th>\n",
              "      <td>0.726626</td>\n",
              "      <td>0.724385</td>\n",
              "      <td>0.725337</td>\n",
              "      <td>0.727326</td>\n",
              "      <td>0.724785</td>\n",
              "      <td>0.725692</td>\n",
              "      <td>0.724709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_2</th>\n",
              "      <td>0.726026</td>\n",
              "      <td>0.725339</td>\n",
              "      <td>0.726025</td>\n",
              "      <td>0.727015</td>\n",
              "      <td>0.723650</td>\n",
              "      <td>0.725611</td>\n",
              "      <td>0.724312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_10</th>\n",
              "      <td>0.723002</td>\n",
              "      <td>0.724125</td>\n",
              "      <td>0.726679</td>\n",
              "      <td>0.727765</td>\n",
              "      <td>0.724918</td>\n",
              "      <td>0.725298</td>\n",
              "      <td>0.724643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_13</th>\n",
              "      <td>0.726188</td>\n",
              "      <td>0.725868</td>\n",
              "      <td>0.724457</td>\n",
              "      <td>0.726574</td>\n",
              "      <td>0.723165</td>\n",
              "      <td>0.725250</td>\n",
              "      <td>0.724821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_14</th>\n",
              "      <td>0.726635</td>\n",
              "      <td>0.723331</td>\n",
              "      <td>0.726652</td>\n",
              "      <td>0.726307</td>\n",
              "      <td>0.722684</td>\n",
              "      <td>0.725122</td>\n",
              "      <td>0.724677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_5</th>\n",
              "      <td>0.724562</td>\n",
              "      <td>0.725678</td>\n",
              "      <td>0.726044</td>\n",
              "      <td>0.726695</td>\n",
              "      <td>0.720412</td>\n",
              "      <td>0.724678</td>\n",
              "      <td>0.724052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_6</th>\n",
              "      <td>0.725134</td>\n",
              "      <td>0.723587</td>\n",
              "      <td>0.724750</td>\n",
              "      <td>0.724656</td>\n",
              "      <td>0.722338</td>\n",
              "      <td>0.724093</td>\n",
              "      <td>0.723838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_11</th>\n",
              "      <td>0.724360</td>\n",
              "      <td>0.721621</td>\n",
              "      <td>0.724134</td>\n",
              "      <td>0.725047</td>\n",
              "      <td>0.723051</td>\n",
              "      <td>0.723642</td>\n",
              "      <td>0.723001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_8</th>\n",
              "      <td>0.726310</td>\n",
              "      <td>0.721494</td>\n",
              "      <td>0.722096</td>\n",
              "      <td>0.723774</td>\n",
              "      <td>0.722089</td>\n",
              "      <td>0.723153</td>\n",
              "      <td>0.722150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_0</th>\n",
              "      <td>0.721843</td>\n",
              "      <td>0.718059</td>\n",
              "      <td>0.720634</td>\n",
              "      <td>0.720957</td>\n",
              "      <td>0.718352</td>\n",
              "      <td>0.719969</td>\n",
              "      <td>0.718930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_12</th>\n",
              "      <td>0.715258</td>\n",
              "      <td>0.715772</td>\n",
              "      <td>0.716382</td>\n",
              "      <td>0.719162</td>\n",
              "      <td>0.716568</td>\n",
              "      <td>0.716628</td>\n",
              "      <td>0.716017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_4</th>\n",
              "      <td>0.719038</td>\n",
              "      <td>0.714977</td>\n",
              "      <td>0.714792</td>\n",
              "      <td>0.719312</td>\n",
              "      <td>0.714353</td>\n",
              "      <td>0.716494</td>\n",
              "      <td>0.715829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_9</th>\n",
              "      <td>0.714727</td>\n",
              "      <td>0.714949</td>\n",
              "      <td>0.719028</td>\n",
              "      <td>0.719080</td>\n",
              "      <td>0.714218</td>\n",
              "      <td>0.716401</td>\n",
              "      <td>0.716170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a268d01-6072-4fff-8385-ee0c2de1ae74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a268d01-6072-4fff-8385-ee0c2de1ae74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a268d01-6072-4fff-8385-ee0c2de1ae74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp['avg'] = premu_imp.mean(axis=1)\n",
        "premu_imp.sort_values('avg', ascending=False, inplace=True)\n",
        "oof.sort_values('oof', ascending=False, inplace=True)"
      ],
      "metadata": {
        "id": "XoqQJPPJdGd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp.sort_values('avg', ascending=False, inplace=True)"
      ],
      "metadata": {
        "id": "W9tkYiP_9nAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp['med'] = premu_imp.median(axis=1)"
      ],
      "metadata": {
        "id": "p8SBDkaYs7ZX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(premu_imp.loc[premu_imp.med > 0], x='med', bins=150, height=5, legend=False,  aspect=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "Zc8YicBuQupw",
        "outputId": "34426639-edde-4b2f-c44a-0419608acfac"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f9c2a14b8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAFgCAYAAACmDI9oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYfUlEQVR4nO3df7Bmd10f8PfHbC4/jCYEttuYUDYK44TSHWGuKRXHWqJjqpbQNjKxVqNg046r1dKqgNNhquMMTgV/TYqTIZTYIpAiDvFHsRSiTGsNLqAbchM0hRA2XdhFZI2VGjb59I/7AN9cN7t3797nOffH6zXzzD7ne359niffc+87537POdXdAQAAVn3R1AUAAMBWIiADAMBAQAYAgIGADAAAAwEZAAAGe6Yu4FxcffXV/Y53vGPqMgAA2J7qVI3b+gzyJz/5yalLAABgh9nWARkAADabgAwAAAMBGQAABgIyAAAMBGQAABgIyAAAMBCQAQBgMLeAXFWvr6pjVfXBoe3fV9U9VXW4qn61qi4a5r28qu6tqg9V1TfNqy4AADideZ5BfkOSq9e0vTPJs7r7QJI/SvLyJKmqZya5LsnfnK3zH6rqvDnWBgAApzS3gNzd70nyqTVt/627T84mfy/JZbP31yR5c3f/ZXd/JMm9Sa6cV20AAPBYphyD/OIk/3X2/tIkHxvmHZm1AQDAQk0SkKvqx5KcTPLGDax7Q1UdqqpDx48f3/ziAADY1fYseodV9d1JvjXJVd3ds+YHkjx1WOyyWdtf0d03JbkpSZaXl/tUy8zTQw89lMOHDz+q7cCBA1laWlp0KQAAzMFCA3JVXZ3kR5L83e7+i2HWbUl+uapek+TLkjwjyXsXWdt6HT58OAdvvC0XXrI/SXLi6H258WCyvLw8aV0AAGyOuQXkqnpTkq9P8pSqOpLklVm9a8XjkryzqpLk97r7X3T3XVV1a5KVrA69ONjdD8+rtnN14SX7c/H+K6YuAwCAOZhbQO7ubz9F882nWf4nk/zkvOoBAID18CQ9AAAYCMgAADAQkAEAYCAgAwDAQEAGAICBgAwAAAMBGQAABgIyAAAMBGQAABgIyAAAMBCQAQBgICADAMBAQAYAgIGADAAAAwEZAAAGAjIAAAwEZAAAGAjIAAAwEJABAGAgIAMAwEBABgCAgYAMAAADARkAAAYCMgAADARkAAAYCMgAADAQkAEAYCAgAwDAQEAGAICBgAwAAAMBGQAABgIyAAAMBGQAABgIyAAAMBCQAQBgICADAMBAQAYAgIGADAAAAwEZAAAGAjIAAAwEZAAAGMwtIFfV66vqWFV9cGi7uKreWVV/PPv3SbP2qqqfr6p7q+pwVT1nXnUBAMDpzPMM8huSXL2m7WVJ3tXdz0jyrtl0kvz9JM+YvW5I8to51gUAAI9pbgG5u9+T5FNrmq9Jcsvs/S1JXji0/1Kv+r0kF1XVJfOqDQAAHsuixyDv6+6js/cfT7Jv9v7SJB8bljsya/srquqGqjpUVYeOHz8+v0oBANiVJrtIr7s7SW9gvZu6e7m7l/fu3TuHygAA2M0WHZA/8bmhE7N/j83aH0jy1GG5y2ZtAACwUIsOyLcluX72/vokbx/av2t2N4vnJjkxDMUAAICF2TOvDVfVm5J8fZKnVNWRJK9M8qokt1bVS5J8NMmLZov/ZpJvTnJvkr9I8j3zqmuzPfLwyaysrDyq7cCBA1laWpqoIgAAzsXcAnJ3f/tjzLrqFMt2koPzqmWeHjx2JK++/zPZd8/JJMmJo/flxoPJ8vLytIUBALAhcwvIu8kF+56Wi/dfMXUZAABsAo+aBgCAgYAMAAADARkAAAYCMgAADARkAAAYCMgAADAQkAEAYCAgAwDAQEAGAICBgAwAAAMBGQAABgIyAAAMBGQAABgIyAAAMBCQAQBgICADAMBAQAYAgIGADAAAAwEZAAAGAjIAAAwEZAAAGAjIAAAwEJABAGAgIAMAwEBABgCAgYAMAAADARkAAAYCMgAADARkAAAYCMgAADAQkAEAYCAgAwDAQEAGAICBgAwAAAMBGQAABgIyAAAMBGQAABgIyAAAMBCQAQBgMElArqp/VVV3VdUHq+pNVfX4qrq8qu6oqnur6i1VtTRFbQAA7G4LD8hVdWmSf5lkubufleS8JNcl+akkP9PdT0/yp0lesujaAABgqiEWe5I8oar2JHlikqNJnp/krbP5tyR54US1AQCwiy08IHf3A0l+Osn9WQ3GJ5K8L8mnu/vkbLEjSS491fpVdUNVHaqqQ8ePH19EyQAA7CJTDLF4UpJrklye5MuSfHGSq9e7fnff1N3L3b28d+/eOVUJAMBuNcUQi29I8pHuPt7dn03ytiTPS3LRbMhFklyW5IEJagMAYJebIiDfn+S5VfXEqqokVyVZSXJ7kmtny1yf5O0T1AYAwC43xRjkO7J6Md77k9w5q+GmJD+a5KVVdW+SJye5edG1AQDAnjMvsvm6+5VJXrmm+cNJrpygHAAA+DxP0gMAgIGADAAAAwEZAAAGAjIAAAwEZAAAGAjIAAAwEJABAGAgIAMAwEBABgCAgYAMAAADARkAAAYCMgAADARkAAAYCMgAADAQkAEAYCAgAwDAQEAGAICBgAwAAAMBGQAABgIyAAAMBGQAABgIyAAAMBCQAQBgICADAMBAQAYAgMG6AnJVPW89bQAAsN2t9wzyL6yzDQAAtrU9p5tZVX8nydck2VtVLx1mfWmS8+ZZGAAATOG0ATnJUpILZst9ydD+Z0munVdRAAAwldMG5O7+nSS/U1Vv6O6PLqgmAACYzJnOIH/O46rqpiT7x3W6+/nzKAoAAKay3oD8X5L8YpLXJXl4fuUAAMC01huQT3b3a+daCQAAbAHrvc3br1XV91XVJVV18edec60MAAAmsN4zyNfP/v3hoa2TfPnmlgMAANNaV0Du7svnXQgAAGwF6wrIVfVdp2rv7l/a3HIAAGBa6x1i8dXD+8cnuSrJ+5MIyAAA7CjrHWLxA+N0VV2U5M1zqQgAACa03rtYrPV/kxiXDADAjrPeMci/ltW7ViTJeUmuSHLrRnc6OwP9uiTPmm33xUk+lOQtWX1a331JXtTdf7rRfQAAwEasdwzyTw/vTyb5aHcfOYf9/lySd3T3tVW1lOSJSV6R5F3d/aqqelmSlyX50XPYBwAAnLV1DbHo7t9Jck+SL0nypCQPbXSHVXVhkq9LcvNs2w9196eTXJPkltlityR54Ub3AQAAG7WugFxVL0ry3iTfluRFSe6oqms3uM/LkxxP8h+r6gNV9bqq+uIk+7r76GyZjyfZ9xi13FBVh6rq0PHjxzdYAgAAnNp6L9L7sSRf3d3Xd/d3Jbkyyb/d4D73JHlOktd297OzesHfy8YFurvzhTHPWTPvpu5e7u7lvXv3brAEAAA4tfUG5C/q7mPD9J+cxbprHUlypLvvmE2/NauB+RNVdUmSzP499hjrAwDA3Kw35L6jqn6rqr67qr47yW8k+c2N7LC7P57kY1X1lbOmq5KsJLktyfWztuuTvH0j2wcAgHNx2rtYVNXTszo2+Ier6h8l+drZrP+V5I3nsN8fSPLG2R0sPpzke7Ia1m+tqpck+WhWxzoDAMBCnek2bz+b5OVJ0t1vS/K2JKmqvzWb9w82stPu/oMky6eYddVGtgcAAJvlTEMs9nX3nWsbZ23751IRAABM6EwB+aLTzHvCZhYCAABbwZkC8qGq+mdrG6vqe5O8bz4lAQDAdM40BvmHkvxqVX1HvhCIl5MsJfmH8ywMAACmcNqA3N2fSPI1VfX3kjxr1vwb3f3uuVcGAAATONMZ5CRJd9+e5PY51wIAAJPb6NPwAABgRxKQAQBgICADAMBAQAYAgIGADAAAAwEZAAAGAjIAAAwEZAAAGAjIAAAwEJABAGAgIAMAwEBABgCAgYAMAAADARkAAAYCMgAADARkAAAYCMgAADAQkAEAYCAgAwDAQEAGAICBgAwAAAMBGQAABgIyAAAMBGQAABgIyAAAMBCQAQBgICADAMBAQAYAgIGADAAAAwEZAAAGAjIAAAwEZAAAGAjIAAAwEJABAGAwWUCuqvOq6gNV9euz6cur6o6qureq3lJVS1PVBgDA7jXlGeQfTHL3MP1TSX6mu5+e5E+TvGSSqgAA2NUmCchVdVmSb0nyutl0JXl+krfOFrklyQunqA0AgN1tqjPIP5vkR5I8Mpt+cpJPd/fJ2fSRJJeeasWquqGqDlXVoePHj8+/UgAAdpWFB+Sq+tYkx7r7fRtZv7tv6u7l7l7eu3fvJlcHAMBut2eCfT4vyQuq6puTPD7Jlyb5uSQXVdWe2Vnky5I8MEFtAADscgs/g9zdL+/uy7p7f5Lrkry7u78jye1Jrp0tdn2Sty+6NgAA2Er3Qf7RJC+tqnuzOib55onrAQBgF5piiMXndfdvJ/nt2fsPJ7lyynoAAGArnUEGAIDJCcgAADAQkAEAYCAgAwDAQEAGAICBgAwAAAMBGQAABgIyAAAMBGQAABgIyAAAMBCQAQBgICADAMBAQAYAgMGeqQvYaR55+GRWVlYe1XbgwIEsLS1NVBEAAGdDQN5kDx47klff/5nsu+dkkuTE0fty48FkeXl52sIAAFgXAXkOLtj3tFy8/4qpywAAYAOMQQYAgIGADAAAAwEZAAAGAjIAAAwEZAAAGAjIAAAwEJABAGAgIAMAwEBABgCAgYAMAAADARkAAAYCMgAADPZMXcBO98jDJ7OysvKotgMHDmRpaWmiigAAOB0Bec4ePHYkr77/M9l3z8kkyYmj9+XGg8ny8vK0hQEAcEoC8gJcsO9puXj/FVOXAQDAOhiDDAAAAwEZAAAGAjIAAAwEZAAAGAjIAAAwEJABAGAgIAMAwEBABgCAgYAMAACDhQfkqnpqVd1eVStVdVdV/eCs/eKqemdV/fHs3yctujYAAJjiDPLJJP+6u5+Z5LlJDlbVM5O8LMm7uvsZSd41mwYAgIVaeEDu7qPd/f7Z+weT3J3k0iTXJLllttgtSV646NoAAGDSMchVtT/Js5PckWRfdx+dzfp4kn0TlQUAwC42WUCuqguS/EqSH+ruPxvndXcn6cdY74aqOlRVh44fP76ASgEA2E32TLHTqjo/q+H4jd39tlnzJ6rqku4+WlWXJDl2qnW7+6YkNyXJ8vLyKUP0dvLQQw/l8OHDj2o7cOBAlpaWJqoIAGB3W3hArqpKcnOSu7v7NcOs25Jcn+RVs3/fvujapnD48OEcvPG2XHjJ/iTJiaP35caDyfLy8qR1AQDsVlOcQX5eku9McmdV/cGs7RVZDca3VtVLknw0yYsmqG0SF16yPxfvv2LqMgAAyAQBubv/R5J6jNlXLbIWAABYy5P0AABgICADAMBAQAYAgIGADAAAAwEZAAAGAjIAAAwEZAAAGAjIAAAwEJABAGAgIAMAwEBABgCAwZ6pC9htHnn4ZFZWVj4/vbKyku6esCIAAEYC8oI9eOxIXn3/Z7LvnpNJkgfu/N1c9BVflSdPXBcAAKsE5AlcsO9puXj/FUmSE0fve9S8tWeYk+TAgQNZWlpaUHUAALubgLzFrD3DfOLofbnxYLK8vDxtYQAAu4SAvAWNZ5gBAFgsd7EAAICBgAwAAAMBGQAABgIyAAAMBGQAABgIyAAAMBCQAQBgICADAMBAQAYAgIGADAAAAwEZAAAGAjIAAAz2TF0AZ+ehhx7K4cOHH9V24MCBLC0tbcryAAC7nYC8zRw+fDgHb7wtF16yP0ly4uh9ufFgsry8vCnLAwDsdgLyFvfIwyezsrLy+emVlZV86V9/Wi7ef8W6t3HhJfvPankAgN1MQN7iHjx2JK++/zPZd8/JJMkDd/5uLvqKr8qTJ64LAGCnEpC3gQv2feGM8Ymj901aCwDATicg7zJrh2wkLtoDABgJyLvM2iEbLtoDAHg0AXmHWXtbt5WVlXT3o5YZh2wsmtvOsVOca19eu/5nP/vZJMn555+/oe1tdn0Au5mAvMOsva3bVruoz23n2CnOtS+f6ljdc8GTsu/yL1xvcC7HhmMNYOME5B1ovK3bVryoz23n2CnOtS+vPVb3XPjXNvXYcKwBbIyAzKOc6c+y2+3PttutXuZrnv3bBbAAO4eAzKOc6c+y2+3PttutXuZrnv3bBbAAO4eAvMtt5El9Z/Nn2/VcNHg265/pQqZT7e9snzx4Lpyxnq/N+H7P1H/H+WuPj7H/ne0FsGd7LJxu36eaTuZ7Ud+8+/bZbn+zL5Jcu75jmdFO6y/neryd68+f7fB9bbmAXFVXJ/m5JOcleV13v2rikna0eT+p71wvGjzbC5mmvkjRGev5WvT3e6rj43P9bzP68unWP92+TzU974v65v3dn+32N/siye3+1zLma6f1l3M93s715892+L62VECuqvOS3JjkG5McSfL7VXVbd6+cfk3Oxbyf1HeuFw2e7YVMU1+k6MKo+Vr097v2+Phc/9uMvrzRfZ9qejOczdn1eTjb7W/mRZLz2D47y07rL+dyvG3Gz5+t/n1tqYCc5Mok93b3h5Okqt6c5JokWyogj7/Y/vyT/yd7/t9n8qknPnGS6RNH78vKyhf+M66srGxqfWfa/tr5a52pns1e/1z3d67O9vvh7Jzr93um9c/m+Jn62Jz3sXqu2ztbm13vue7Pscxop/WXRf8uX8/+kwPrXn8R6mzGg85bVV2b5Oru/t7Z9Hcm+dvd/f3DMjckuWE2+ZVJPrTwQpOnJPnkBPtl+9FXWC99hfXSV1gvfeXMPtndV69t3Lr/e/MYuvumJDdNWUNVHerurTNQhi1LX2G99BXWS19hvfSVjfuiqQtY44EkTx2mL5u1AQDAQmy1gPz7SZ5RVZdX1VKS65LcNnFNAADsIltqiEV3n6yq70/yW1m9zdvru/uuics6lUmHeLCt6Cusl77CeukrrJe+skFb6iI9AACY2lYbYgEAAJMSkAEAYCAgZ/Xx1lX1oaq6t6pedor5j6uqt8zm31FV+4d5L5+1f6iqvmm922R7mlNfeX1VHauqDy7mU7AIm91XquqpVXV7Va1U1V1V9YOL+zTM0xz6yuOr6r1V9YezvvLvFvdpmKd5/A6azTuvqj5QVb8+/0+xTXT3rn5l9WLA/53ky5MsJfnDJM9cs8z3JfnF2fvrkrxl9v6Zs+Ufl+Ty2XbOW882vbbfax59ZTbv65I8J8kHp/6MXlu3ryS5JMlzZst8SZI/8nNl+7/m1FcqyQWzZc5PckeS5079Wb22Xl8Z1ntpkl9O8utTf86t8nIGeXi8dXc/lORzj7ceXZPkltn7tya5qqpq1v7m7v7L7v5Ikntn21vPNtl+5tFX0t3vSfKpRXwAFmbT+0p3H+3u9ydJdz+Y5O4kly7gszBf8+gr3d1/Plv+/NnLFfnb31x+B1XVZUm+JcnrFvAZtg0BefUXzMeG6SP5q790Pr9Md59MciLJk0+z7nq2yfYzj77CzjTXvjL7s+mzs3pmkO1tLn1l9ifzP0hyLMk7u1tf2f7m9XPlZ5P8SJJHNr/k7UtABthGquqCJL+S5Ie6+8+mroetqbsf7u6vyuoTaa+sqmdNXRNbT1V9a5Jj3f2+qWvZagTk9T3e+vPLVNWeJBcm+ZPTrOuR2TvTPPoKO9Nc+kpVnZ/VcPzG7n7bXCpn0eb6c6W7P53k9iRXb2rVTGEefeV5SV5QVfdldcjG86vqP8+j+O1GQF7f461vS3L97P21Sd7dq6Pab0ty3eyq0cuTPCPJe9e5TbafefQVdqZN7yuzcYQ3J7m7u1+zkE/BIsyjr+ytqouSpKqekOQbk9yzgM/CfG16X+nul3f3Zd29f7a9d3f3P13Eh9nqttSjpqfQj/F466r68SSHuvu2rP5S+k9VdW9WL6a6brbuXVV1a5KVJCeTHOzuh5PkVNtc9Gdjc82xr7wpydcneUpVHUnyyu6+ecEfj000j75SVV+b5DuT3DkbW5okr+ju31zsp2MzzamvXJLklqo6L6snwm7tbrfv2ubm9TuIU/OoaQAAGBhiAQAAAwEZAAAGAjIAAAwEZAAAGAjIAAAwEJABdrGq+u2qWp66DoCtREAGAICBgAywzVTV/qq6p6reUFV/VFVvrKpvqKr/WVV/XFVXVtUXV9Xrq+q9VfWBqrpmtu4TqurNVXV3Vf1qkidM/HEAtpxd/yQ9gG3q6Um+LcmLs/oI2n+S5GuTvCDJK7L6xKx3d/eLZ48dfm9V/fck/zzJX3T3FVV1IMn7J6keYAsTkAG2p490951JUlV3JXlXd3dV3Zlkf5LLkrygqv7NbPnHJ/kbSb4uyc8nSXcfrqrDC68cYIsTkAG2p78c3j8yTD+S1Z/tDyf5x939oXGlqlpMdQDbmDHIADvTbyX5gZol4qp69qz9PVkdjpGqelaSA9OUB7B1CcgAO9NPJDk/yeHZEIyfmLW/NskFVXV3kh9P8r6J6gPYsqq7p64BAAC2DGeQAQBgICADAMBAQAYAgIGADAAAAwEZAAAGAjIAAAwEZAAAGPx/4ur69CsOY/wAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp.sort_values('med', ascending=False, inplace=True)"
      ],
      "metadata": {
        "id": "lzuTzBIx4CR8"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Parameter & Feature Order"
      ],
      "metadata": {
        "id": "pyV1SFNx006n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# order_0_model_104 0.726660 order_0_model_187 0.723227"
      ],
      "metadata": {
        "id": "M7DaLkbe0pni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter     = pd.DataFrame([xgb_grid[7], xgb_grid[7]], index = ['avg', 'oof'])\n",
        "\n",
        "order_avg   = [x[0] for x in orders[0]]\n",
        "weights_avg = [x[1] for x in orders[0]]\n",
        "\n",
        "order_oof   = [x[0] for x in orders[0]]\n",
        "weights_oof = [x[1] for x in orders[0]]\n",
        "\n",
        "feature_order = pd.DataFrame(list(zip(order_avg, weights_avg, order_oof, weights_oof)), columns=['order_avg', 'weights_avg', 'order_oof', 'weights_oof'])"
      ],
      "metadata": {
        "id": "bGxfvq_vRJO_"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter.to_csv('/content/drive/MyDrive/KaggleAMEX/Models/freq_3/parameters.csv') \n",
        "feature_order.to_csv('/content/drive/MyDrive/KaggleAMEX/Models/freq_3/features.csv')"
      ],
      "metadata": {
        "id": "Mho5u8_SwBT_"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter = pd.read_csv('/content/drive/MyDrive/KaggleAMEX/Models/freq_3/parameters.csv', index_col=0)\n",
        "order     = pd.read_csv('/content/drive/MyDrive/KaggleAMEX/Models/freq_3/features.csv', index_col=0)"
      ],
      "metadata": {
        "id": "WbDAQITWzYcr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPVVjUz5Byxx"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzD_A0XoJxaT"
      },
      "source": [
        "https://towardsdatascience.com/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7\n",
        "\n",
        "Gain - The relative contribution of the corresponding feature to the model. This is calculated by taking each feature’s contribution for each tree in the model. A higher value of this metric when compared to another feature implies it is more important for generating a prediction.\n",
        "\n",
        "Coverage - The relative number of observations related to this feature. For example, if you have 100 observations, 4 features and 3 trees, and suppose feature1 is used to decide the leaf node for 10, 5, and 2 observations in tree1, tree2 and tree3 respectively; then the metric will count cover for this feature as 10+5+2 = 17 observations. This will be calculated for all the 4 features and the cover will be 17 expressed as a percentage for all features’ cover metrics.\n",
        "\n",
        "Weight - The percentage representing the relative number of times a particular feature occurs in the trees of the model. In the above example, if feature1 occurred in 2 splits, 1 split and 3 splits in each of tree1, tree2 and tree3; then the weight for feature1 will be 2+1+3 = 6. The frequency for feature1 is calculated as its percentage weight over weights of all features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3ByAb_HGhUQ"
      },
      "outputs": [],
      "source": [
        "importance_types = ['cover', 'gain', 'weight', 'total_gain', 'total_cover']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipDndrnyLw3R"
      },
      "outputs": [],
      "source": [
        "df = model.get_score(importance_type='cover')\n",
        "df = pd.DataFrame.from_dict(df, orient='index', columns = ['cover'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHAbQxOOOdV3"
      },
      "outputs": [],
      "source": [
        "df = model.get_score(importance_type='gain')\n",
        "df = pd.DataFrame.from_dict(df, orient='index', columns = ['gain'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "0_Lz0gyTjumy",
        "8rX6N4YTs4-U",
        "OPVVjUz5Byxx"
      ],
      "machine_shape": "hm",
      "name": "Train/Test.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}