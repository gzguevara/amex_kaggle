{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gzguevara/amex_kaggle/blob/master/Train_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrb7n4eJF27U"
      },
      "source": [
        "# Import Drive and XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Han3-fXyTN6j",
        "outputId": "05d37502-ed70-4f39-961a-b5b6c9a5a9f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found existing installation: xgboost 0.90\n",
            "Uninstalling xgboost-0.90:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/xgboost-0.90.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/xgboost/*\n",
            "    /usr/local/xgboost/libxgboost.so\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled xgboost-0.90\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 192.9 MB 52 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n",
            "Installing collected packages: xgboost\n",
            "Successfully installed xgboost-1.6.1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip uninstall xgboost\n",
        "!pip install xgboost\n",
        "\n",
        "#!pip install import_ipynb\n",
        "#import import_ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_Lz0gyTjumy"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7Fj6oq8fQhsm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy  as np  \n",
        "import cupy\n",
        "# for cupu memory managmet\n",
        "mempool        = cupy.get_default_memory_pool()\n",
        "pinned_mempool = cupy.get_default_pinned_memory_pool()\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import sys\n",
        "from importlib import reload #test = reload(test)\n",
        "\n",
        "import matplotlib.pyplot as plt, gc, os\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "# Paths\n",
        "train_dir   = '/content/drive/MyDrive/KaggleAMEX/Data/train.parquet'\n",
        "impor_dir   = '/content/drive/MyDrive/KaggleAMEX/Importance'\n",
        "targets_dir = '/content/drive/MyDrive/KaggleAMEX/Data/train_labels.csv'\n",
        "\n",
        "#Parameters\n",
        "SEED  = 42\n",
        "FOLDS = 5\n",
        "\n",
        "#Get numerical and catecorical columns \n",
        "\n",
        "cat_features = ['B_30', 'B_38', 'D_117', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68', 'B_33', 'D_92', 'D_103', 'R_27', 'D_114', 'D_116', 'D_129', 'D_139', 'D_140', 'D_143', 'B_8', 'D_51', 'D_54', 'D_65', 'B_16', 'B_22', 'D_72', 'D_78', 'D_79', 'R_9', 'D_82', 'D_107', 'D_122', 'D_125']\n",
        "bin_features = ['R_2', 'S_6', 'R_4', 'R_15', 'S_18', 'D_86', 'D_87', 'B_31', 'R_19', 'B_32', 'S_20', 'R_21', 'R_22', 'R_23', 'D_93', 'D_94', 'R_24', 'R_25', 'D_96', 'D_127', 'R_28', 'D_109', 'D_120', 'D_135', 'D_137', 'R_7', 'R_12', 'R_14', 'D_112']\n",
        "num_features = ['P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'D_46', 'D_47', 'D_48', 'D_49', 'B_6', 'B_7', 'D_50', 'B_9', 'R_3', 'D_52', 'P_3', 'B_10', 'D_53', 'S_5', 'B_11', 'S_7', 'B_12', 'S_8', 'D_55', 'D_56', 'B_13', 'R_5', 'D_58', 'S_9', 'B_14', 'D_59', 'D_60', 'D_61', 'B_15', 'S_11', 'D_62', 'B_17', 'B_18', 'B_19', 'B_20', 'S_12', 'R_6', 'S_13', 'B_21', 'D_69', 'D_70', 'D_71', 'S_15', 'B_23', 'D_73', 'P_4', 'D_74', 'D_75', 'D_76', 'B_24', 'D_77', 'B_25', 'B_26', 'R_8', 'S_16', 'D_80', 'R_10', 'R_11', 'B_27', 'D_81', 'S_17', 'B_28', 'R_13', 'D_83', 'D_84', 'R_16', 'B_29', 'R_17', 'R_18', 'D_88', 'S_19', 'R_20', 'D_89', 'D_91', 'S_22', 'S_23', 'S_24', 'S_25', 'S_26', 'D_102', 'D_104', 'D_105', 'D_106', 'B_36', 'B_37', 'R_26', 'D_108', 'D_110', 'D_111', 'B_39', 'B_40', 'S_27', 'D_113', 'D_115', 'D_118', 'D_119', 'D_121', 'D_123', 'D_124', 'D_128', 'B_41', 'B_42', 'D_130', 'D_131', 'D_132', 'D_133', 'D_134', 'D_136', 'D_138', 'D_141', 'D_142', 'D_144', 'D_145']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juv-r73KS3a_"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "crYzLkbkPWsP"
      },
      "outputs": [],
      "source": [
        "def process_and_feature_engineer(cus_range, obs):\n",
        "\n",
        "    # 13\n",
        "    frequency = pd.read_csv('/content/drive/MyDrive/KaggleAMEX/Data/train/frequency.csv', index_col=0)\n",
        "    customers = frequency.loc[frequency.frequency.isin(cus_range)].index.values\n",
        "    \n",
        "    # num - mean, std, min, max, last, first  cat - last, unique\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/base_variables.parquet'\n",
        "    df  = pd.read_parquet(dir)\n",
        "    df  = df.loc[customers]\n",
        "    # replace categorial\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/base_variables_cat_woe.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df[new.columns] = new\n",
        "    print('Done base', df.shape)\n",
        "    \n",
        "    # p_b_s_r_d variables corr and cat/bin sum \n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/p_b_s_r_d.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers, ['R_sum_num', 'S_bin_sum', 'D_bin_sum', 'R_bin_sum', 'B_cat_sum', 'D_cat_sum']]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done p_b_s_r_d variables', df.shape)\n",
        "    \n",
        "    # count na & not na values\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/mean_na.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done count na variables', df.shape)\n",
        "\n",
        "    # non linear numerical\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/nonlinear.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done non linear', df.shape)\n",
        "\n",
        "    # First difference of last values \n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/first_diff.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done diff_1 variables', df.shape)\n",
        "    \n",
        "    # Sum woe numerical\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/num_woe_sum.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done sum woe', df.shape)\n",
        "\n",
        "    # Advanced\n",
        "    dir = '/content/drive/MyDrive/KaggleAMEX/Data/train/advanced.parquet'\n",
        "    new = pd.read_parquet(dir)\n",
        "    new = new.loc[customers]\n",
        "    df  = pd.concat([new, df], axis=1)\n",
        "    print('Done advanced features', df.shape)\n",
        "\n",
        "    # Add targets\n",
        "    targets      = pd.read_csv(targets_dir, usecols = ['target']).astype('int8')\n",
        "    df['target'] = targets.loc[customers]\n",
        "\n",
        "    # Drop na columns\n",
        "    to_drop = [x for x in df.columns if len(df[x].unique())==1]\n",
        "    df.drop(to_drop, axis=1, inplace=True)\n",
        "    print(f'Droped {len(to_drop)} features. New Shape:', df.shape)\n",
        "\n",
        "    # Reset index\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Downsample majority class\n",
        "    df_majority = df.loc[df.target == 0]\n",
        "    df_minority = df.loc[df.target == 1]\n",
        "\n",
        "    df_majority = resample(df_majority, \n",
        "                          replace      = False,    \n",
        "                          n_samples    = df_minority.shape[0], # int(obs/2),  \n",
        "                          random_state = SEED)\n",
        "    '''\n",
        "    df_minority = resample(df_minority, \n",
        "                          replace      = False,    \n",
        "                          n_samples    = int(obs/2), \n",
        "                          random_state = SEED)\n",
        "    '''\n",
        "    df = pd.concat([df_majority, df_minority])\n",
        "    df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "    print('Downsampled to', df.shape)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KOqHWr4Qhso"
      },
      "source": [
        "# Read & Transform Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNhMjOowI7P2",
        "outputId": "cf09db88-bea6-49f3-a2f2-fa3bd89bab63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done base (386034, 829)\n",
            "Done p_b_s_r_d variables (386034, 835)\n",
            "Done count na variables (386034, 1213)\n",
            "Done non linear (386034, 1395)\n",
            "Done diff_1 variables (386034, 1541)\n",
            "Done sum woe (386034, 1668)\n",
            "Done advanced features (386034, 1913)\n",
            "Droped 139 features. New Shape: (386034, 1774)\n",
            "Downsampled to (178956, 1774)\n"
          ]
        }
      ],
      "source": [
        "train = process_and_feature_engineer(cus_range=[13], obs=5000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[order.order_avg.to_list() + ['target']]"
      ],
      "metadata": {
        "id": "X6rs9UFMzdhH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqSKKYASQhsv"
      },
      "source": [
        "# Extreme Gradient Boost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rX6N4YTs4-U"
      },
      "source": [
        "### Custom metric & permutation importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MeDwbg2Os4tb"
      },
      "outputs": [],
      "source": [
        "# This is the metric given by rules\n",
        "def amex_metric_mod(y_true, y_pred):\n",
        "\n",
        "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
        "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
        "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
        "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
        "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
        "\n",
        "    gini = [0,0]\n",
        "    for i in [1,0]:\n",
        "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
        "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
        "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
        "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
        "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
        "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
        "        lorentz        = cum_pos_found / total_pos\n",
        "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
        "\n",
        "\n",
        "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
        "    \n",
        "\n",
        "# Metric for XGB\n",
        "def xgboost_amex_metric_mod(predt: np.ndarray, dtrain: xgb.DMatrix):\n",
        "    y = dtrain.get_label()\n",
        "    return 'AMEXcustom', 1-amex_metric_mod(y, predt)\n",
        "\n",
        "def permutation_importance(train, valid_idx, features, model, kag_mets):\n",
        "\n",
        "    # Permutation importance\n",
        "    x_test  = train.loc[valid_idx, train.columns[:-1]]\n",
        "    y_test  = train.loc[valid_idx, 'target']\n",
        "    metrics = []\n",
        "\n",
        "    for column, feature in enumerate(features):\n",
        "\n",
        "          #Save original feature\n",
        "          original_feature = x_test[feature].copy()\n",
        "          metric = []\n",
        "\n",
        "          for i in range(1):\n",
        "\n",
        "              # Shuffel\n",
        "              x_test[feature] = np.random.permutation(original_feature)\n",
        "\n",
        "              #Build DMatrix\n",
        "              dvalid = xgb.DMatrix(data=cupy.array(x_test))\n",
        "              \n",
        "              #Predict\n",
        "              preds  = model.predict(dvalid, iteration_range=(0, model.best_iteration + 1))\n",
        "              metric.append(kag_mets - amex_metric_mod(y_test, preds))\n",
        "\n",
        "          metrics.append(np.mean(metric))\n",
        "\n",
        "          #Rebuild data\n",
        "          x_test[feature] = original_feature\n",
        "    \n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP8vVxNQs3CR"
      },
      "source": [
        "### Get grid & feature order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ4A0OlhDfdw",
        "outputId": "8b161f0c-0ed1-4816-a592-f2a90754eb55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 30 different Models. \n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "learning_rate     = [0.02, 0.0225, 0.025, 0.0275, 0.03]          \n",
        "gamma             = [0.005]\n",
        "\n",
        "max_depth         = [4,5]                     \n",
        "max_leaves        = [0, 10, 20]             \n",
        "max_bin           = [200]               \n",
        "\n",
        "subsample         = [0.1, 0.2, 0.3]   \n",
        "sampling_method   = ['gradient_based'] #'uniform', \n",
        "\n",
        "colsample_bytree  = [1]             \n",
        "colsample_bylevel = [1]             \n",
        "colsample_bynode  = [0.2]             \n",
        "                   \n",
        "alpha             = [0, 0.25, 0.5, 0.75, 1, 1.25, 1.5]             \n",
        "lambda_           = [1, 1.1, 1.2, 1.3]             \n",
        "\n",
        "min_child_weight  = [1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8]    \n",
        "scale_pos_weight  = [1]\n",
        "\n",
        "grow_policy       = ['depthwise']\n",
        "\n",
        "tree_method       = ['gpu_hist']        \n",
        "objective         = ['binary:logistic']\n",
        "predictor         = ['gpu_predictor']\n",
        "seed              = [SEED]\n",
        "\n",
        "booster           = ['dart']\n",
        "sample_type       = ['uniform', 'weighted']\n",
        "normalize_type    = ['tree', 'forest']\n",
        "rate_drop         = [0.1, 0.2]\n",
        "skip_drop         = [0.5, 0.6]\n",
        "\n",
        "\n",
        "# Get Grids for xgb\n",
        "hyper_parms = ['grow_policy', 'learning_rate', 'gamma', 'max_depth', 'min_child_weight', 'subsample', 'sampling_method', 'colsample_bytree', 'colsample_bylevel', 'colsample_bynode', 'lambda', 'alpha', 'scale_pos_weight', 'max_leaves', 'max_bin', 'tree_method', 'objective', 'predictor', 'seed']#, 'booster', 'sample_type', 'normalize_type', 'rate_drop', 'skip_drop']\n",
        "variants    = list(itertools.product(grow_policy, learning_rate, gamma, max_depth, min_child_weight, subsample, sampling_method, colsample_bytree, colsample_bylevel, colsample_bynode, lambda_, alpha, scale_pos_weight, max_leaves, max_bin, tree_method, objective, predictor, seed))#, booster, sample_type, normalize_type, rate_drop, skip_drop))\n",
        "xgb_grid    = [dict(zip(hyper_parms, variant)) for variant in variants]\n",
        "random.shuffle(xgb_grid)\n",
        "xgb_grid = xgb_grid[:100]\n",
        "\n",
        "print(f'There are {len(xgb_grid)} different Models.', '\\n', '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp = premu_imp.loc[premu_imp.avg > 0.00015].copy()"
      ],
      "metadata": {
        "id": "46JAyWi-6jLT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[premu_imp.index.to_list() + ['target']]"
      ],
      "metadata": {
        "id": "61cqAz0V6q5E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp['weight'] = [0] * premu_imp.shape[0]"
      ],
      "metadata": {
        "id": "MUJTKPhG9kNc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp['weight'] = premu_imp['avg']"
      ],
      "metadata": {
        "id": "9fq50y0Z9rI4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp.loc[premu_imp.avg>0.0015]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Bwq6T7uWGP4k",
        "outputId": "9a3e8ef2-9b69-4621-ed1b-47fb7f969495"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 order_2_grid_0_fold_0  order_2_grid_0_fold_1  \\\n",
              "B_4_std                       0.012781               0.014258   \n",
              "R_1_p_B_9_last                0.011860               0.013168   \n",
              "D_39_max                      0.008637               0.014250   \n",
              "R_1_last                      0.006912               0.012892   \n",
              "cat_sum                       0.004036               0.010072   \n",
              "...                                ...                    ...   \n",
              "D_50_first                    0.000864               0.002016   \n",
              "B_18_std                      0.002008               0.000044   \n",
              "B_23_d_B_2_last              -0.000068               0.000020   \n",
              "D_50_max                      0.003004               0.003651   \n",
              "D_105_mean                    0.004032               0.012112   \n",
              "\n",
              "                 order_2_grid_0_fold_2  order_2_grid_0_fold_3  \\\n",
              "B_4_std                       0.007697               0.032499   \n",
              "R_1_p_B_9_last                0.005000               0.025633   \n",
              "D_39_max                      0.004056               0.006677   \n",
              "R_1_last                      0.008886               0.011445   \n",
              "cat_sum                       0.003932               0.010852   \n",
              "...                                ...                    ...   \n",
              "D_50_first                    0.002052               0.000156   \n",
              "B_18_std                      0.001072              -0.000032   \n",
              "B_23_d_B_2_last               0.001028               0.002932   \n",
              "D_50_max                      0.001128               0.002128   \n",
              "D_105_mean                    0.001068               0.000008   \n",
              "\n",
              "                 order_2_grid_0_fold_4  order_2_grid_1_fold_0  \\\n",
              "B_4_std                       0.006900               0.020561   \n",
              "R_1_p_B_9_last                0.007813               0.010593   \n",
              "D_39_max                      0.002381               0.000176   \n",
              "R_1_last                      0.006008               0.000056   \n",
              "cat_sum                       0.007437               0.012092   \n",
              "...                                ...                    ...   \n",
              "D_50_first                   -0.000016               0.002972   \n",
              "B_18_std                      0.000000               0.016056   \n",
              "B_23_d_B_2_last              -0.000120               0.001016   \n",
              "D_50_max                     -0.001000               0.000156   \n",
              "D_105_mean                    0.000016              -0.000004   \n",
              "\n",
              "                 order_2_grid_1_fold_1  order_2_grid_1_fold_2  \\\n",
              "B_4_std                       0.001349               0.010797   \n",
              "R_1_p_B_9_last                0.020389               0.009168   \n",
              "D_39_max                      0.000305               0.020709   \n",
              "R_1_last                      0.008868               0.017793   \n",
              "cat_sum                       0.009232               0.007048   \n",
              "...                                ...                    ...   \n",
              "D_50_first                    0.001984               0.000924   \n",
              "B_18_std                     -0.000008               0.003060   \n",
              "B_23_d_B_2_last               0.002112               0.003960   \n",
              "D_50_max                     -0.000176              -0.000020   \n",
              "D_105_mean                    0.000156               0.001056   \n",
              "\n",
              "                 order_2_grid_1_fold_3  order_2_grid_1_fold_4  ...  \\\n",
              "B_4_std                       0.013641               0.009601  ...   \n",
              "R_1_p_B_9_last                0.016164               0.007541  ...   \n",
              "D_39_max                      0.007679               0.000024  ...   \n",
              "R_1_last                     -0.000196               0.007549  ...   \n",
              "cat_sum                       0.012036               0.005509  ...   \n",
              "...                                ...                    ...  ...   \n",
              "D_50_first                    0.000289               0.000092  ...   \n",
              "B_18_std                      0.000032               0.000000  ...   \n",
              "B_23_d_B_2_last              -0.000072               0.000888  ...   \n",
              "D_50_max                      0.000060               0.005397  ...   \n",
              "D_105_mean                   -0.000060               0.000000  ...   \n",
              "\n",
              "                 order_0_grid_1_fold_2  order_0_grid_1_fold_3  \\\n",
              "B_4_std                       0.017789               0.024366   \n",
              "R_1_p_B_9_last                0.006509               0.011192   \n",
              "D_39_max                      0.017132               0.007736   \n",
              "R_1_last                      0.003613               0.001944   \n",
              "cat_sum                       0.002988               0.004601   \n",
              "...                                ...                    ...   \n",
              "D_50_first                    0.001080               0.004124   \n",
              "B_18_std                      0.000072               0.001004   \n",
              "B_23_d_B_2_last               0.002048               0.000064   \n",
              "D_50_max                     -0.000004               0.003289   \n",
              "D_105_mean                    0.005068               0.003160   \n",
              "\n",
              "                 order_0_grid_1_fold_4  order_0_grid_2_fold_0  \\\n",
              "B_4_std                       0.005728               0.000076   \n",
              "R_1_p_B_9_last                0.017022              -0.000016   \n",
              "D_39_max                      0.000609               0.000846   \n",
              "R_1_last                      0.008597               0.000120   \n",
              "cat_sum                      -0.000591               0.000317   \n",
              "...                                ...                    ...   \n",
              "D_50_first                    0.000020               0.000204   \n",
              "B_18_std                     -0.000104               0.000056   \n",
              "B_23_d_B_2_last               0.001108               0.000008   \n",
              "D_50_max                     -0.000812              -0.000016   \n",
              "D_105_mean                   -0.000064               0.000108   \n",
              "\n",
              "                 order_0_grid_2_fold_1  order_0_grid_2_fold_2  \\\n",
              "B_4_std                       0.012523               0.024030   \n",
              "R_1_p_B_9_last               -0.002188              -0.001014   \n",
              "D_39_max                      0.005573              -0.000385   \n",
              "R_1_last                      0.006449               0.020765   \n",
              "cat_sum                       0.018465               0.003968   \n",
              "...                                ...                    ...   \n",
              "D_50_first                    0.004924              -0.000092   \n",
              "B_18_std                      0.004044               0.000016   \n",
              "B_23_d_B_2_last               0.004080               0.000140   \n",
              "D_50_max                      0.002880               0.000124   \n",
              "D_105_mean                    0.007088               0.000148   \n",
              "\n",
              "                 order_0_grid_2_fold_3  order_0_grid_2_fold_4       avg  \\\n",
              "B_4_std                       0.021110               0.018180  0.010757   \n",
              "R_1_p_B_9_last                0.013693              -0.000599  0.009108   \n",
              "D_39_max                      0.014619               0.003256  0.007949   \n",
              "R_1_last                      0.012301               0.004192  0.007054   \n",
              "cat_sum                       0.002681               0.004024  0.006507   \n",
              "...                                ...                    ...       ...   \n",
              "D_50_first                    0.001389               0.005485  0.001530   \n",
              "B_18_std                     -0.000060              -0.000048  0.001529   \n",
              "B_23_d_B_2_last               0.000004               0.004800  0.001529   \n",
              "D_50_max                      0.002256              -0.001880  0.001511   \n",
              "D_105_mean                    0.003176              -0.000188  0.001503   \n",
              "\n",
              "                   weight  \n",
              "B_4_std          0.010757  \n",
              "R_1_p_B_9_last   0.009108  \n",
              "D_39_max         0.007949  \n",
              "R_1_last         0.007054  \n",
              "cat_sum          0.006507  \n",
              "...                   ...  \n",
              "D_50_first       0.001530  \n",
              "B_18_std         0.001529  \n",
              "B_23_d_B_2_last  0.001529  \n",
              "D_50_max         0.001511  \n",
              "D_105_mean       0.001503  \n",
              "\n",
              "[188 rows x 47 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf9926bc-c358-49b3-992b-686fd1569a70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_2_grid_0_fold_0</th>\n",
              "      <th>order_2_grid_0_fold_1</th>\n",
              "      <th>order_2_grid_0_fold_2</th>\n",
              "      <th>order_2_grid_0_fold_3</th>\n",
              "      <th>order_2_grid_0_fold_4</th>\n",
              "      <th>order_2_grid_1_fold_0</th>\n",
              "      <th>order_2_grid_1_fold_1</th>\n",
              "      <th>order_2_grid_1_fold_2</th>\n",
              "      <th>order_2_grid_1_fold_3</th>\n",
              "      <th>order_2_grid_1_fold_4</th>\n",
              "      <th>...</th>\n",
              "      <th>order_0_grid_1_fold_2</th>\n",
              "      <th>order_0_grid_1_fold_3</th>\n",
              "      <th>order_0_grid_1_fold_4</th>\n",
              "      <th>order_0_grid_2_fold_0</th>\n",
              "      <th>order_0_grid_2_fold_1</th>\n",
              "      <th>order_0_grid_2_fold_2</th>\n",
              "      <th>order_0_grid_2_fold_3</th>\n",
              "      <th>order_0_grid_2_fold_4</th>\n",
              "      <th>avg</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B_4_std</th>\n",
              "      <td>0.012781</td>\n",
              "      <td>0.014258</td>\n",
              "      <td>0.007697</td>\n",
              "      <td>0.032499</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>0.020561</td>\n",
              "      <td>0.001349</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>0.013641</td>\n",
              "      <td>0.009601</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017789</td>\n",
              "      <td>0.024366</td>\n",
              "      <td>0.005728</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.012523</td>\n",
              "      <td>0.024030</td>\n",
              "      <td>0.021110</td>\n",
              "      <td>0.018180</td>\n",
              "      <td>0.010757</td>\n",
              "      <td>0.010757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_1_p_B_9_last</th>\n",
              "      <td>0.011860</td>\n",
              "      <td>0.013168</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.025633</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.010593</td>\n",
              "      <td>0.020389</td>\n",
              "      <td>0.009168</td>\n",
              "      <td>0.016164</td>\n",
              "      <td>0.007541</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006509</td>\n",
              "      <td>0.011192</td>\n",
              "      <td>0.017022</td>\n",
              "      <td>-0.000016</td>\n",
              "      <td>-0.002188</td>\n",
              "      <td>-0.001014</td>\n",
              "      <td>0.013693</td>\n",
              "      <td>-0.000599</td>\n",
              "      <td>0.009108</td>\n",
              "      <td>0.009108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_39_max</th>\n",
              "      <td>0.008637</td>\n",
              "      <td>0.014250</td>\n",
              "      <td>0.004056</td>\n",
              "      <td>0.006677</td>\n",
              "      <td>0.002381</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.020709</td>\n",
              "      <td>0.007679</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017132</td>\n",
              "      <td>0.007736</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.000846</td>\n",
              "      <td>0.005573</td>\n",
              "      <td>-0.000385</td>\n",
              "      <td>0.014619</td>\n",
              "      <td>0.003256</td>\n",
              "      <td>0.007949</td>\n",
              "      <td>0.007949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_1_last</th>\n",
              "      <td>0.006912</td>\n",
              "      <td>0.012892</td>\n",
              "      <td>0.008886</td>\n",
              "      <td>0.011445</td>\n",
              "      <td>0.006008</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.008868</td>\n",
              "      <td>0.017793</td>\n",
              "      <td>-0.000196</td>\n",
              "      <td>0.007549</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003613</td>\n",
              "      <td>0.001944</td>\n",
              "      <td>0.008597</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.006449</td>\n",
              "      <td>0.020765</td>\n",
              "      <td>0.012301</td>\n",
              "      <td>0.004192</td>\n",
              "      <td>0.007054</td>\n",
              "      <td>0.007054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_sum</th>\n",
              "      <td>0.004036</td>\n",
              "      <td>0.010072</td>\n",
              "      <td>0.003932</td>\n",
              "      <td>0.010852</td>\n",
              "      <td>0.007437</td>\n",
              "      <td>0.012092</td>\n",
              "      <td>0.009232</td>\n",
              "      <td>0.007048</td>\n",
              "      <td>0.012036</td>\n",
              "      <td>0.005509</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002988</td>\n",
              "      <td>0.004601</td>\n",
              "      <td>-0.000591</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.018465</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0.002681</td>\n",
              "      <td>0.004024</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>0.006507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_50_first</th>\n",
              "      <td>0.000864</td>\n",
              "      <td>0.002016</td>\n",
              "      <td>0.002052</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>-0.000016</td>\n",
              "      <td>0.002972</td>\n",
              "      <td>0.001984</td>\n",
              "      <td>0.000924</td>\n",
              "      <td>0.000289</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001080</td>\n",
              "      <td>0.004124</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.004924</td>\n",
              "      <td>-0.000092</td>\n",
              "      <td>0.001389</td>\n",
              "      <td>0.005485</td>\n",
              "      <td>0.001530</td>\n",
              "      <td>0.001530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_18_std</th>\n",
              "      <td>0.002008</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.001072</td>\n",
              "      <td>-0.000032</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016056</td>\n",
              "      <td>-0.000008</td>\n",
              "      <td>0.003060</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.001004</td>\n",
              "      <td>-0.000104</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.004044</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>-0.000060</td>\n",
              "      <td>-0.000048</td>\n",
              "      <td>0.001529</td>\n",
              "      <td>0.001529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_23_d_B_2_last</th>\n",
              "      <td>-0.000068</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.002932</td>\n",
              "      <td>-0.000120</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>0.002112</td>\n",
              "      <td>0.003960</td>\n",
              "      <td>-0.000072</td>\n",
              "      <td>0.000888</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002048</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.001108</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.004080</td>\n",
              "      <td>0.000140</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.004800</td>\n",
              "      <td>0.001529</td>\n",
              "      <td>0.001529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_50_max</th>\n",
              "      <td>0.003004</td>\n",
              "      <td>0.003651</td>\n",
              "      <td>0.001128</td>\n",
              "      <td>0.002128</td>\n",
              "      <td>-0.001000</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>-0.000176</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.005397</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.003289</td>\n",
              "      <td>-0.000812</td>\n",
              "      <td>-0.000016</td>\n",
              "      <td>0.002880</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>0.002256</td>\n",
              "      <td>-0.001880</td>\n",
              "      <td>0.001511</td>\n",
              "      <td>0.001511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_105_mean</th>\n",
              "      <td>0.004032</td>\n",
              "      <td>0.012112</td>\n",
              "      <td>0.001068</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.001056</td>\n",
              "      <td>-0.000060</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005068</td>\n",
              "      <td>0.003160</td>\n",
              "      <td>-0.000064</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>0.007088</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.003176</td>\n",
              "      <td>-0.000188</td>\n",
              "      <td>0.001503</td>\n",
              "      <td>0.001503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>188 rows × 47 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf9926bc-c358-49b3-992b-686fd1569a70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf9926bc-c358-49b3-992b-686fd1569a70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf9926bc-c358-49b3-992b-686fd1569a70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp.loc[premu_imp.avg>0.0015, 'weight'] = premu_imp.loc[premu_imp.avg>0.0015, 'weight'] + 0.015"
      ],
      "metadata": {
        "id": "os016MMP-5Ly"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp['weight'] = premu_imp.weight / premu_imp.weight.sum()"
      ],
      "metadata": {
        "id": "_1DNf2_c_zFi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get orders\n",
        "orders  = []\n",
        "\n",
        "weights = premu_imp.weight.to_list()       # order.weights_avg.to_list()  [1/len(train.columns[:-1])] * len(train.columns[:-1])  # \n",
        "cols    = train.columns[:-1].to_list()     # train.columns[:-1].to_list() \n",
        "\n",
        "join = list(zip(cols, weights))\n",
        "\n",
        "for order in range(3):\n",
        "\n",
        "  random.shuffle(join)\n",
        "  orders.append(join.copy())\n",
        "\n",
        "print(f'There are {len(orders)} different order.', '\\n', '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLr8h5TPXREt",
        "outputId": "6de9c9bb-6ae6-4bfb-e66a-5d3811e1bb02"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3 different order. \n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search & Permutation Importance"
      ],
      "metadata": {
        "id": "P9_RnCF-1wvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMAdr01JQhsw",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6713e4-53ef-4e83-918c-14b85127459f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########### Order 0 Model 0 Fold 0 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67640\tvalid-AMEXcustom:0.35149\n",
            "[500]\tvalid-logloss:0.23611\tvalid-AMEXcustom:0.25762\n",
            "[1000]\tvalid-logloss:0.23123\tvalid-AMEXcustom:0.25457\n",
            "[1500]\tvalid-logloss:0.22994\tvalid-AMEXcustom:0.25001\n",
            "[1988]\tvalid-logloss:0.22937\tvalid-AMEXcustom:0.25013\n",
            "Metric = 0.7520237891960697, Best = nan \n",
            "\n",
            "########### Order 0 Model 0 Fold 1 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67637\tvalid-AMEXcustom:0.34196\n",
            "[500]\tvalid-logloss:0.23906\tvalid-AMEXcustom:0.25569\n",
            "[1000]\tvalid-logloss:0.23379\tvalid-AMEXcustom:0.25152\n",
            "[1500]\tvalid-logloss:0.23232\tvalid-AMEXcustom:0.25117\n",
            "[1602]\tvalid-logloss:0.23214\tvalid-AMEXcustom:0.25075\n",
            "Metric = 0.7497443640979942, Best = nan \n",
            "\n",
            "########### Order 0 Model 0 Fold 2 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67645\tvalid-AMEXcustom:0.34962\n",
            "[500]\tvalid-logloss:0.24078\tvalid-AMEXcustom:0.26233\n",
            "[1000]\tvalid-logloss:0.23627\tvalid-AMEXcustom:0.25881\n",
            "[1500]\tvalid-logloss:0.23495\tvalid-AMEXcustom:0.25874\n",
            "[2000]\tvalid-logloss:0.23444\tvalid-AMEXcustom:0.25866\n",
            "[2140]\tvalid-logloss:0.23440\tvalid-AMEXcustom:0.25882\n",
            "Metric = 0.7422578867473839, Best = nan \n",
            "\n",
            "########### Order 0 Model 0 Fold 3 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67639\tvalid-AMEXcustom:0.34430\n",
            "[500]\tvalid-logloss:0.23769\tvalid-AMEXcustom:0.25924\n",
            "[1000]\tvalid-logloss:0.23292\tvalid-AMEXcustom:0.25346\n",
            "[1500]\tvalid-logloss:0.23166\tvalid-AMEXcustom:0.25384\n",
            "[1676]\tvalid-logloss:0.23141\tvalid-AMEXcustom:0.25367\n",
            "Metric = 0.7471055331444477, Best = nan \n",
            "\n",
            "########### Order 0 Model 0 Fold 4 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67640\tvalid-AMEXcustom:0.35892\n",
            "[500]\tvalid-logloss:0.23838\tvalid-AMEXcustom:0.26258\n",
            "[1000]\tvalid-logloss:0.23402\tvalid-AMEXcustom:0.25992\n",
            "[1500]\tvalid-logloss:0.23296\tvalid-AMEXcustom:0.26074\n",
            "[2000]\tvalid-logloss:0.23248\tvalid-AMEXcustom:0.25691\n",
            "[2500]\tvalid-logloss:0.23200\tvalid-AMEXcustom:0.25654\n",
            "[2869]\tvalid-logloss:0.23186\tvalid-AMEXcustom:0.25538\n",
            "Metric = 0.744844702988245, Best = nan \n",
            "\n",
            "avg: 0.7471952552348281, Max: 0.7471952552348281\n",
            "oof: 0.746552227002778, Max: 0.746552227002778 \n",
            " \n",
            " \n",
            "\n",
            "########### Order 0 Model 1 Fold 0 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67922\tvalid-AMEXcustom:0.35999\n",
            "[500]\tvalid-logloss:0.23753\tvalid-AMEXcustom:0.25977\n",
            "[1000]\tvalid-logloss:0.23224\tvalid-AMEXcustom:0.25429\n",
            "[1500]\tvalid-logloss:0.23076\tvalid-AMEXcustom:0.25051\n",
            "[1820]\tvalid-logloss:0.23042\tvalid-AMEXcustom:0.25153\n",
            "Metric = 0.7502788845325425, Best = 0.7520237891960697 \n",
            "\n",
            "########### Order 0 Model 1 Fold 1 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67937\tvalid-AMEXcustom:0.34914\n",
            "[500]\tvalid-logloss:0.24079\tvalid-AMEXcustom:0.25874\n",
            "[1000]\tvalid-logloss:0.23483\tvalid-AMEXcustom:0.25294\n",
            "[1500]\tvalid-logloss:0.23305\tvalid-AMEXcustom:0.25156\n",
            "[2000]\tvalid-logloss:0.23271\tvalid-AMEXcustom:0.25091\n",
            "[2471]\tvalid-logloss:0.23246\tvalid-AMEXcustom:0.25082\n",
            "Metric = 0.7507681422878809, Best = 0.7507681422878809 \n",
            "\n",
            "########### Order 0 Model 1 Fold 2 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67934\tvalid-AMEXcustom:0.36702\n",
            "[500]\tvalid-logloss:0.24208\tvalid-AMEXcustom:0.26097\n",
            "[1000]\tvalid-logloss:0.23670\tvalid-AMEXcustom:0.25555\n",
            "[1500]\tvalid-logloss:0.23514\tvalid-AMEXcustom:0.25661\n",
            "[1542]\tvalid-logloss:0.23509\tvalid-AMEXcustom:0.25564\n",
            "Metric = 0.7457726299097852, Best = 0.7457726299097852 \n",
            "\n",
            "########### Order 0 Model 1 Fold 3 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67929\tvalid-AMEXcustom:0.40078\n",
            "[500]\tvalid-logloss:0.23856\tvalid-AMEXcustom:0.25932\n",
            "[1000]\tvalid-logloss:0.23342\tvalid-AMEXcustom:0.25442\n",
            "[1500]\tvalid-logloss:0.23195\tvalid-AMEXcustom:0.25406\n",
            "[1737]\tvalid-logloss:0.23158\tvalid-AMEXcustom:0.25307\n",
            "Metric = 0.7479348737386924, Best = 0.7479348737386924 \n",
            "\n",
            "########### Order 0 Model 1 Fold 4 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.67929\tvalid-AMEXcustom:0.35142\n",
            "[500]\tvalid-logloss:0.23984\tvalid-AMEXcustom:0.26486\n",
            "[1000]\tvalid-logloss:0.23453\tvalid-AMEXcustom:0.25686\n",
            "[1500]\tvalid-logloss:0.23314\tvalid-AMEXcustom:0.25614\n",
            "[1895]\tvalid-logloss:0.23274\tvalid-AMEXcustom:0.25577\n",
            "Metric = 0.7449866566682597, Best = 0.7449866566682597 \n",
            "\n",
            "avg: 0.7479482374274322, Max: 0.7479482374274322\n",
            "oof: 0.7474730959700528, Max: 0.7474730959700528 \n",
            " \n",
            " \n",
            "\n",
            "########### Order 0 Model 2 Fold 0 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.68025\tvalid-AMEXcustom:0.35098\n",
            "[500]\tvalid-logloss:0.23509\tvalid-AMEXcustom:0.25849\n",
            "[1000]\tvalid-logloss:0.23232\tvalid-AMEXcustom:0.25800\n",
            "[1123]\tvalid-logloss:0.23204\tvalid-AMEXcustom:0.25788\n",
            "Metric = 0.7444303698793568, Best = 0.7520237891960697 \n",
            "\n",
            "########### Order 0 Model 2 Fold 1 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.68035\tvalid-AMEXcustom:0.34540\n",
            "[500]\tvalid-logloss:0.23734\tvalid-AMEXcustom:0.25324\n",
            "[1000]\tvalid-logloss:0.23377\tvalid-AMEXcustom:0.25118\n",
            "[1372]\tvalid-logloss:0.23311\tvalid-AMEXcustom:0.24990\n",
            "Metric = 0.7505547125903222, Best = 0.7507681422878809 \n",
            "\n",
            "########### Order 0 Model 2 Fold 2 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.68038\tvalid-AMEXcustom:0.35837\n",
            "[500]\tvalid-logloss:0.23887\tvalid-AMEXcustom:0.26022\n",
            "[994]\tvalid-logloss:0.23560\tvalid-AMEXcustom:0.25894\n",
            "Metric = 0.7427446124730679, Best = 0.7457726299097852 \n",
            "\n",
            "########### Order 0 Model 2 Fold 3 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.68031\tvalid-AMEXcustom:0.34933\n",
            "[500]\tvalid-logloss:0.23661\tvalid-AMEXcustom:0.25657\n",
            "[1000]\tvalid-logloss:0.23323\tvalid-AMEXcustom:0.25486\n",
            "[1071]\tvalid-logloss:0.23312\tvalid-AMEXcustom:0.25447\n",
            "Metric = 0.7472081566609844, Best = 0.7479348737386924 \n",
            "\n",
            "########### Order 0 Model 2 Fold 4 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.68036\tvalid-AMEXcustom:0.34239\n",
            "[500]\tvalid-logloss:0.23743\tvalid-AMEXcustom:0.26260\n",
            "[1000]\tvalid-logloss:0.23456\tvalid-AMEXcustom:0.26143\n",
            "[1061]\tvalid-logloss:0.23446\tvalid-AMEXcustom:0.26121\n",
            "Metric = 0.7400960928375926, Best = 0.7449866566682597 \n",
            "\n",
            "avg: 0.7450067888882648, Max: 0.7479482374274322\n",
            "oof: 0.7443242548859368, Max: 0.7474730959700528 \n",
            " \n",
            " \n",
            "\n",
            "########### Order 0 Model 3 Fold 0 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.68072\tvalid-AMEXcustom:0.38315\n",
            "[500]\tvalid-logloss:0.23940\tvalid-AMEXcustom:0.26081\n",
            "[1000]\tvalid-logloss:0.23267\tvalid-AMEXcustom:0.25542\n",
            "[1500]\tvalid-logloss:0.23066\tvalid-AMEXcustom:0.25276\n",
            "[2000]\tvalid-logloss:0.22985\tvalid-AMEXcustom:0.25194\n",
            "[2313]\tvalid-logloss:0.22948\tvalid-AMEXcustom:0.25269\n",
            "Metric = 0.7486777833040108, Best = 0.7520237891960697 \n",
            "\n",
            "########### Order 0 Model 3 Fold 1 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.68083\tvalid-AMEXcustom:0.34487\n",
            "[500]\tvalid-logloss:0.24282\tvalid-AMEXcustom:0.25813\n",
            "[1000]\tvalid-logloss:0.23553\tvalid-AMEXcustom:0.25281\n",
            "[1500]\tvalid-logloss:0.23322\tvalid-AMEXcustom:0.24880\n",
            "[2000]\tvalid-logloss:0.23232\tvalid-AMEXcustom:0.24886\n",
            "[2500]\tvalid-logloss:0.23186\tvalid-AMEXcustom:0.24767\n",
            "[2786]\tvalid-logloss:0.23169\tvalid-AMEXcustom:0.24781\n",
            "Metric = 0.7532478931430261, Best = 0.7532478931430261 \n",
            "\n",
            "########### Order 0 Model 3 Fold 2 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.68094\tvalid-AMEXcustom:0.35027\n",
            "[500]\tvalid-logloss:0.24446\tvalid-AMEXcustom:0.26443\n",
            "[1000]\tvalid-logloss:0.23766\tvalid-AMEXcustom:0.25859\n",
            "[1500]\tvalid-logloss:0.23571\tvalid-AMEXcustom:0.25691\n",
            "[2000]\tvalid-logloss:0.23495\tvalid-AMEXcustom:0.25751\n",
            "[2063]\tvalid-logloss:0.23486\tvalid-AMEXcustom:0.25734\n",
            "Metric = 0.7442758758582146, Best = 0.7457726299097852 \n",
            "\n",
            "########### Order 0 Model 3 Fold 3 #############\n",
            "##################################################\n",
            "[0]\tvalid-logloss:0.68093\tvalid-AMEXcustom:0.34823\n",
            "[500]\tvalid-logloss:0.24079\tvalid-AMEXcustom:0.26045\n",
            "[1000]\tvalid-logloss:0.23405\tvalid-AMEXcustom:0.25481\n"
          ]
        }
      ],
      "source": [
        "# Out-of-fold predictions & permutation  importances\n",
        "oof_cols  = [f'fold_{i}' for i in range(FOLDS)] + ['avg', 'oof']\n",
        "oof       = pd.DataFrame(columns = oof_cols)\n",
        "premu_imp = pd.DataFrame()\n",
        "\n",
        "# Get feature order & weights\n",
        "for order_num, order in enumerate(orders):\n",
        "\n",
        "      weights     = [x[1] for x in order]\n",
        "      features    = [x[0] for x in order]\n",
        "      train       = train[features + ['target']]\n",
        "      premu_order = pd.DataFrame(index=train.columns[:-1])\n",
        "\n",
        "      # Start grid search\n",
        "      for model_num, xgb_parms in enumerate(xgb_grid):\n",
        "\n",
        "            kag_mets  = []\n",
        "            oof_model = pd.DataFrame()\n",
        "\n",
        "            # Start cross validation\n",
        "            skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=11)\n",
        "            for fold, (train_idx, valid_idx) in enumerate(skf.split(train, train.target)):\n",
        "                \n",
        "                  print(f'########### Order {order_num} Model {model_num} Fold {fold} #############')\n",
        "                  print('##################################################')\n",
        "                  \n",
        "                  # Train and valid set for given fold       \n",
        "                  x_valid = cupy.array(train.loc[valid_idx, train.columns[:-1]])\n",
        "                  y_valid = cupy.array(train.loc[valid_idx, 'target'])\n",
        "                  dvalid  = xgb.DMatrix(data=x_valid, label=y_valid)\n",
        "                  \n",
        "                  x_train = cupy.array(train.loc[train_idx, train.columns[:-1]])\n",
        "                  y_train = cupy.array(train.loc[train_idx, 'target'])\n",
        "                  dtrain  = xgb.DeviceQuantileDMatrix(data=x_train, label=y_train, feature_weights=weights)\n",
        "\n",
        "                  # Train model\n",
        "                  model = xgb.train(params                = xgb_parms,\n",
        "                                    dtrain                = dtrain,\n",
        "                                    evals                 = [(dvalid,'valid')],\n",
        "                                    custom_metric         = xgboost_amex_metric_mod,\n",
        "                                    num_boost_round       = 10000,\n",
        "                                    early_stopping_rounds = 300,\n",
        "                                    verbose_eval          = 500)\n",
        "                \n",
        "                  # Save model\n",
        "                  #model_dir = '/content/drive/MyDrive/KaggleAMEX/Models/freq_3'\n",
        "                  #model.save_model(f'{model_dir}/avg_fold_{fold}.xgb')\n",
        "                          \n",
        "                  # Validation - Infer out-of-fold\n",
        "                  preds     = model.predict(dvalid, iteration_range=(0, model.best_iteration + 1))\n",
        "                  df        = pd.DataFrame(data=preds, index=valid_idx, columns=['oof'])\n",
        "                  oof_model = pd.concat([oof_model, df], axis = 0)\n",
        "\n",
        "                  # Kaggle metric\n",
        "                  kag_mets.append(amex_metric_mod(y_valid.get(), preds))\n",
        "                  curr_best = np.max([oof[f'fold_{fold}'].max(), kag_mets[-1]])\n",
        "                  print(f'Metric = {kag_mets[-1]}, Best = {curr_best}', '\\n')\n",
        "                  \n",
        "                  # Skip if no significant improvment\n",
        "                  #if kag_mets[-1] + 0.02 < curr_best: break\n",
        "                  \n",
        "                  # Permutation importance\n",
        "                  #premu_order[f'order_{order_num}_grid_{model_num}_fold_{fold}'] = permutation_importance(train, valid_idx, train.columns[:-1], model, kag_mets[-1])\n",
        "                  \n",
        "                  # Clean RAM & GPU RAM\n",
        "                  del y_train, x_train, y_valid, x_valid, dtrain, dvalid, train_idx, valid_idx\n",
        "                  mempool.free_all_blocks(), pinned_mempool.free_all_blocks(), gc.collect()\n",
        "                    \n",
        "            # Skip if fold not compleat\n",
        "            if len(kag_mets) != 5: continue\n",
        "          \n",
        "            # Metrics\n",
        "            kag_mets.append(np.mean(kag_mets))\n",
        "            kag_mets.append(amex_metric_mod(train.target.values, oof_model.sort_index().oof.values))\n",
        "            oof.loc[f'order_{order_num}_model_{model_num}'] = kag_mets\n",
        "            print(f'avg: {kag_mets[-2]}, Max: {oof.avg.max()}')\n",
        "            print(f'oof: {kag_mets[-1]}, Max: {oof.oof.max()}', '\\n', '\\n', '\\n')\n",
        "            \n",
        "      premu_imp = pd.concat([premu_order,premu_imp], axis=1)\n",
        "\n",
        "# Average over folds\n",
        "premu_imp['avg'] = premu_imp.mean(axis=1)\n",
        "premu_imp.sort_values('avg', ascending=False, inplace=True)\n",
        "oof.sort_values('oof', ascending=False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oof.sort_values('avg', ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kZRwc9epSqok",
        "outputId": "5369c25e-8951-4d46-f772-c649cf9442c6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     fold_0    fold_1    fold_2    fold_3    fold_4       avg  \\\n",
              "order_0_model_83   0.647902  0.646324  0.657499  0.660802  0.644455  0.651396   \n",
              "order_0_model_24   0.647737  0.647529  0.654519  0.661066  0.644896  0.651150   \n",
              "order_0_model_32   0.645168  0.646562  0.654700  0.661891  0.646560  0.650976   \n",
              "order_0_model_11   0.649960  0.645310  0.654601  0.657515  0.646521  0.650781   \n",
              "order_0_model_118  0.646827  0.646606  0.656261  0.659063  0.644563  0.650664   \n",
              "...                     ...       ...       ...       ...       ...       ...   \n",
              "order_0_model_6    0.644727  0.642507  0.642768  0.652004  0.634994  0.643400   \n",
              "order_0_model_42   0.641843  0.643802  0.649084  0.649783  0.632084  0.643319   \n",
              "order_0_model_4    0.642385  0.640882  0.644555  0.649284  0.635369  0.642495   \n",
              "order_0_model_116  0.642257  0.639352  0.644487  0.648946  0.637017  0.642412   \n",
              "order_0_model_99   0.644202  0.641999  0.640182  0.647628  0.636682  0.642139   \n",
              "\n",
              "                        oof  \n",
              "order_0_model_83   0.648804  \n",
              "order_0_model_24   0.648958  \n",
              "order_0_model_32   0.647862  \n",
              "order_0_model_11   0.649473  \n",
              "order_0_model_118  0.649711  \n",
              "...                     ...  \n",
              "order_0_model_6    0.642292  \n",
              "order_0_model_42   0.640368  \n",
              "order_0_model_4    0.637154  \n",
              "order_0_model_116  0.641696  \n",
              "order_0_model_99   0.640451  \n",
              "\n",
              "[121 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54aab852-3227-4ae4-b3e9-1427b71f7d5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold_0</th>\n",
              "      <th>fold_1</th>\n",
              "      <th>fold_2</th>\n",
              "      <th>fold_3</th>\n",
              "      <th>fold_4</th>\n",
              "      <th>avg</th>\n",
              "      <th>oof</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>order_0_model_83</th>\n",
              "      <td>0.647902</td>\n",
              "      <td>0.646324</td>\n",
              "      <td>0.657499</td>\n",
              "      <td>0.660802</td>\n",
              "      <td>0.644455</td>\n",
              "      <td>0.651396</td>\n",
              "      <td>0.648804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_24</th>\n",
              "      <td>0.647737</td>\n",
              "      <td>0.647529</td>\n",
              "      <td>0.654519</td>\n",
              "      <td>0.661066</td>\n",
              "      <td>0.644896</td>\n",
              "      <td>0.651150</td>\n",
              "      <td>0.648958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_32</th>\n",
              "      <td>0.645168</td>\n",
              "      <td>0.646562</td>\n",
              "      <td>0.654700</td>\n",
              "      <td>0.661891</td>\n",
              "      <td>0.646560</td>\n",
              "      <td>0.650976</td>\n",
              "      <td>0.647862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_11</th>\n",
              "      <td>0.649960</td>\n",
              "      <td>0.645310</td>\n",
              "      <td>0.654601</td>\n",
              "      <td>0.657515</td>\n",
              "      <td>0.646521</td>\n",
              "      <td>0.650781</td>\n",
              "      <td>0.649473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_118</th>\n",
              "      <td>0.646827</td>\n",
              "      <td>0.646606</td>\n",
              "      <td>0.656261</td>\n",
              "      <td>0.659063</td>\n",
              "      <td>0.644563</td>\n",
              "      <td>0.650664</td>\n",
              "      <td>0.649711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_6</th>\n",
              "      <td>0.644727</td>\n",
              "      <td>0.642507</td>\n",
              "      <td>0.642768</td>\n",
              "      <td>0.652004</td>\n",
              "      <td>0.634994</td>\n",
              "      <td>0.643400</td>\n",
              "      <td>0.642292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_42</th>\n",
              "      <td>0.641843</td>\n",
              "      <td>0.643802</td>\n",
              "      <td>0.649084</td>\n",
              "      <td>0.649783</td>\n",
              "      <td>0.632084</td>\n",
              "      <td>0.643319</td>\n",
              "      <td>0.640368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_4</th>\n",
              "      <td>0.642385</td>\n",
              "      <td>0.640882</td>\n",
              "      <td>0.644555</td>\n",
              "      <td>0.649284</td>\n",
              "      <td>0.635369</td>\n",
              "      <td>0.642495</td>\n",
              "      <td>0.637154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_116</th>\n",
              "      <td>0.642257</td>\n",
              "      <td>0.639352</td>\n",
              "      <td>0.644487</td>\n",
              "      <td>0.648946</td>\n",
              "      <td>0.637017</td>\n",
              "      <td>0.642412</td>\n",
              "      <td>0.641696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>order_0_model_99</th>\n",
              "      <td>0.644202</td>\n",
              "      <td>0.641999</td>\n",
              "      <td>0.640182</td>\n",
              "      <td>0.647628</td>\n",
              "      <td>0.636682</td>\n",
              "      <td>0.642139</td>\n",
              "      <td>0.640451</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54aab852-3227-4ae4-b3e9-1427b71f7d5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54aab852-3227-4ae4-b3e9-1427b71f7d5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54aab852-3227-4ae4-b3e9-1427b71f7d5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp['avg'] = premu_imp.mean(axis=1)\n",
        "premu_imp.sort_values('avg', ascending=False, inplace=True)\n",
        "oof.sort_values('oof', ascending=False, inplace=True)"
      ],
      "metadata": {
        "id": "XoqQJPPJdGd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp.sort_values('avg', ascending=False, inplace=True)"
      ],
      "metadata": {
        "id": "W9tkYiP_9nAa"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(premu_imp.loc[premu_imp.avg > 0.0002], x='avg', bins=150, height=5, legend=False,  aspect=3.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "Zc8YicBuQupw",
        "outputId": "cdb79fe4-ea41-4c2e-9adc-ebb5f516ff39"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7f4805c74190>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1260x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "premu_order.sort_values('avg', ascending=False, inplace=True)"
      ],
      "metadata": {
        "id": "lzuTzBIx4CR8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "premu_imp.loc[premu_imp.avg > 0.0002]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "ul-6n805xKrI",
        "outputId": "8cb8652d-a6ed-4415-80dc-cd365f558610"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    order_2_grid_0_fold_0  order_2_grid_0_fold_1  \\\n",
              "B_4_std                          0.012781               0.014258   \n",
              "R_1_p_B_9_last                   0.011860               0.013168   \n",
              "D_39_max                         0.008637               0.014250   \n",
              "R_1_last                         0.006912               0.012892   \n",
              "cat_sum                          0.004036               0.010072   \n",
              "...                                   ...                    ...   \n",
              "D_80_std                        -0.000008               0.001028   \n",
              "B_20_last                       -0.000016               0.000000   \n",
              "P_3_std                          0.000016               0.000000   \n",
              "D_77_sum_woe                     0.000008               0.002060   \n",
              "P_2_mean_m_R_5_min               0.000020               0.000000   \n",
              "\n",
              "                    order_2_grid_0_fold_2  order_2_grid_0_fold_3  \\\n",
              "B_4_std                          0.007697               0.032499   \n",
              "R_1_p_B_9_last                   0.005000               0.025633   \n",
              "D_39_max                         0.004056               0.006677   \n",
              "R_1_last                         0.008886               0.011445   \n",
              "cat_sum                          0.003932               0.010852   \n",
              "...                                   ...                    ...   \n",
              "D_80_std                        -0.000004              -0.000004   \n",
              "B_20_last                        0.000012               0.000000   \n",
              "P_3_std                          0.004032               0.000020   \n",
              "D_77_sum_woe                    -0.000004               0.000012   \n",
              "P_2_mean_m_R_5_min              -0.000032               0.000000   \n",
              "\n",
              "                    order_2_grid_0_fold_4  order_2_grid_1_fold_0  \\\n",
              "B_4_std                          0.006900               0.020561   \n",
              "R_1_p_B_9_last                   0.007813               0.010593   \n",
              "D_39_max                         0.002381               0.000176   \n",
              "R_1_last                         0.006008               0.000056   \n",
              "cat_sum                          0.007437               0.012092   \n",
              "...                                   ...                    ...   \n",
              "D_80_std                         0.000012              -0.000020   \n",
              "B_20_last                        0.000000               0.000012   \n",
              "P_3_std                          0.001020               0.002056   \n",
              "D_77_sum_woe                     0.000000              -0.000012   \n",
              "P_2_mean_m_R_5_min               0.000000               0.000000   \n",
              "\n",
              "                    order_2_grid_1_fold_1  order_2_grid_1_fold_2  \\\n",
              "B_4_std                          0.001349               0.010797   \n",
              "R_1_p_B_9_last                   0.020389               0.009168   \n",
              "D_39_max                         0.000305               0.020709   \n",
              "R_1_last                         0.008868               0.017793   \n",
              "cat_sum                          0.009232               0.007048   \n",
              "...                                   ...                    ...   \n",
              "D_80_std                        -0.000012               0.002008   \n",
              "B_20_last                        0.000008               0.000036   \n",
              "P_3_std                         -0.000020               0.003008   \n",
              "D_77_sum_woe                    -0.000024              -0.000004   \n",
              "P_2_mean_m_R_5_min               0.000000               0.000000   \n",
              "\n",
              "                    order_2_grid_1_fold_3  order_2_grid_1_fold_4  ...  \\\n",
              "B_4_std                          0.013641               0.009601  ...   \n",
              "R_1_p_B_9_last                   0.016164               0.007541  ...   \n",
              "D_39_max                         0.007679               0.000024  ...   \n",
              "R_1_last                        -0.000196               0.007549  ...   \n",
              "cat_sum                          0.012036               0.005509  ...   \n",
              "...                                   ...                    ...  ...   \n",
              "D_80_std                        -0.000004               0.000000  ...   \n",
              "B_20_last                        0.000028               0.000036  ...   \n",
              "P_3_std                          0.000108              -0.006060  ...   \n",
              "D_77_sum_woe                    -0.000008               0.000000  ...   \n",
              "P_2_mean_m_R_5_min              -0.000008               0.000000  ...   \n",
              "\n",
              "                    order_0_grid_1_fold_1  order_0_grid_1_fold_2  \\\n",
              "B_4_std                          0.020577               0.017789   \n",
              "R_1_p_B_9_last                   0.007098               0.006509   \n",
              "D_39_max                         0.006677               0.017132   \n",
              "R_1_last                         0.002080               0.003613   \n",
              "cat_sum                          0.006537               0.002988   \n",
              "...                                   ...                    ...   \n",
              "D_80_std                         0.000040              -0.002016   \n",
              "B_20_last                        0.001000               0.000000   \n",
              "P_3_std                          0.001120               0.000004   \n",
              "D_77_sum_woe                    -0.001004               0.000008   \n",
              "P_2_mean_m_R_5_min               0.000000               0.000000   \n",
              "\n",
              "                    order_0_grid_1_fold_3  order_0_grid_1_fold_4  \\\n",
              "B_4_std                          0.024366               0.005728   \n",
              "R_1_p_B_9_last                   0.011192               0.017022   \n",
              "D_39_max                         0.007736               0.000609   \n",
              "R_1_last                         0.001944               0.008597   \n",
              "cat_sum                          0.004601              -0.000591   \n",
              "...                                   ...                    ...   \n",
              "D_80_std                        -0.000032              -0.000004   \n",
              "B_20_last                        0.000000               0.000000   \n",
              "P_3_std                          0.000884               0.000076   \n",
              "D_77_sum_woe                    -0.000048              -0.001080   \n",
              "P_2_mean_m_R_5_min               0.000000               0.000000   \n",
              "\n",
              "                    order_0_grid_2_fold_0  order_0_grid_2_fold_1  \\\n",
              "B_4_std                          0.000076               0.012523   \n",
              "R_1_p_B_9_last                  -0.000016              -0.002188   \n",
              "D_39_max                         0.000846               0.005573   \n",
              "R_1_last                         0.000120               0.006449   \n",
              "cat_sum                          0.000317               0.018465   \n",
              "...                                   ...                    ...   \n",
              "D_80_std                        -0.000004               0.006972   \n",
              "B_20_last                        0.000000              -0.000024   \n",
              "P_3_std                          0.000064               0.000916   \n",
              "D_77_sum_woe                     0.000036               0.001104   \n",
              "P_2_mean_m_R_5_min               0.000024              -0.000044   \n",
              "\n",
              "                    order_0_grid_2_fold_2  order_0_grid_2_fold_3  \\\n",
              "B_4_std                          0.024030               0.021110   \n",
              "R_1_p_B_9_last                  -0.001014               0.013693   \n",
              "D_39_max                        -0.000385               0.014619   \n",
              "R_1_last                         0.020765               0.012301   \n",
              "cat_sum                          0.003968               0.002681   \n",
              "...                                   ...                    ...   \n",
              "D_80_std                        -0.000012              -0.000044   \n",
              "B_20_last                        0.000000               0.000028   \n",
              "P_3_std                          0.000064              -0.000020   \n",
              "D_77_sum_woe                     0.000000               0.004032   \n",
              "P_2_mean_m_R_5_min              -0.000060               0.000000   \n",
              "\n",
              "                    order_0_grid_2_fold_4       avg  \n",
              "B_4_std                          0.018180  0.010757  \n",
              "R_1_p_B_9_last                  -0.000599  0.009108  \n",
              "D_39_max                         0.003256  0.007949  \n",
              "R_1_last                         0.004192  0.007054  \n",
              "cat_sum                          0.004024  0.006507  \n",
              "...                                   ...       ...  \n",
              "D_80_std                        -0.001080  0.000202  \n",
              "B_20_last                        0.000000  0.000201  \n",
              "P_3_std                          0.001936  0.000201  \n",
              "D_77_sum_woe                     0.000000  0.000200  \n",
              "P_2_mean_m_R_5_min               0.000000  0.000200  \n",
              "\n",
              "[1089 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e650e126-97b9-4511-a199-7b144a14e062\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_2_grid_0_fold_0</th>\n",
              "      <th>order_2_grid_0_fold_1</th>\n",
              "      <th>order_2_grid_0_fold_2</th>\n",
              "      <th>order_2_grid_0_fold_3</th>\n",
              "      <th>order_2_grid_0_fold_4</th>\n",
              "      <th>order_2_grid_1_fold_0</th>\n",
              "      <th>order_2_grid_1_fold_1</th>\n",
              "      <th>order_2_grid_1_fold_2</th>\n",
              "      <th>order_2_grid_1_fold_3</th>\n",
              "      <th>order_2_grid_1_fold_4</th>\n",
              "      <th>...</th>\n",
              "      <th>order_0_grid_1_fold_1</th>\n",
              "      <th>order_0_grid_1_fold_2</th>\n",
              "      <th>order_0_grid_1_fold_3</th>\n",
              "      <th>order_0_grid_1_fold_4</th>\n",
              "      <th>order_0_grid_2_fold_0</th>\n",
              "      <th>order_0_grid_2_fold_1</th>\n",
              "      <th>order_0_grid_2_fold_2</th>\n",
              "      <th>order_0_grid_2_fold_3</th>\n",
              "      <th>order_0_grid_2_fold_4</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B_4_std</th>\n",
              "      <td>0.012781</td>\n",
              "      <td>0.014258</td>\n",
              "      <td>0.007697</td>\n",
              "      <td>0.032499</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>0.020561</td>\n",
              "      <td>0.001349</td>\n",
              "      <td>0.010797</td>\n",
              "      <td>0.013641</td>\n",
              "      <td>0.009601</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020577</td>\n",
              "      <td>0.017789</td>\n",
              "      <td>0.024366</td>\n",
              "      <td>0.005728</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.012523</td>\n",
              "      <td>0.024030</td>\n",
              "      <td>0.021110</td>\n",
              "      <td>0.018180</td>\n",
              "      <td>0.010757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_1_p_B_9_last</th>\n",
              "      <td>0.011860</td>\n",
              "      <td>0.013168</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.025633</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.010593</td>\n",
              "      <td>0.020389</td>\n",
              "      <td>0.009168</td>\n",
              "      <td>0.016164</td>\n",
              "      <td>0.007541</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007098</td>\n",
              "      <td>0.006509</td>\n",
              "      <td>0.011192</td>\n",
              "      <td>0.017022</td>\n",
              "      <td>-0.000016</td>\n",
              "      <td>-0.002188</td>\n",
              "      <td>-0.001014</td>\n",
              "      <td>0.013693</td>\n",
              "      <td>-0.000599</td>\n",
              "      <td>0.009108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_39_max</th>\n",
              "      <td>0.008637</td>\n",
              "      <td>0.014250</td>\n",
              "      <td>0.004056</td>\n",
              "      <td>0.006677</td>\n",
              "      <td>0.002381</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.000305</td>\n",
              "      <td>0.020709</td>\n",
              "      <td>0.007679</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006677</td>\n",
              "      <td>0.017132</td>\n",
              "      <td>0.007736</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.000846</td>\n",
              "      <td>0.005573</td>\n",
              "      <td>-0.000385</td>\n",
              "      <td>0.014619</td>\n",
              "      <td>0.003256</td>\n",
              "      <td>0.007949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_1_last</th>\n",
              "      <td>0.006912</td>\n",
              "      <td>0.012892</td>\n",
              "      <td>0.008886</td>\n",
              "      <td>0.011445</td>\n",
              "      <td>0.006008</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>0.008868</td>\n",
              "      <td>0.017793</td>\n",
              "      <td>-0.000196</td>\n",
              "      <td>0.007549</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002080</td>\n",
              "      <td>0.003613</td>\n",
              "      <td>0.001944</td>\n",
              "      <td>0.008597</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.006449</td>\n",
              "      <td>0.020765</td>\n",
              "      <td>0.012301</td>\n",
              "      <td>0.004192</td>\n",
              "      <td>0.007054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cat_sum</th>\n",
              "      <td>0.004036</td>\n",
              "      <td>0.010072</td>\n",
              "      <td>0.003932</td>\n",
              "      <td>0.010852</td>\n",
              "      <td>0.007437</td>\n",
              "      <td>0.012092</td>\n",
              "      <td>0.009232</td>\n",
              "      <td>0.007048</td>\n",
              "      <td>0.012036</td>\n",
              "      <td>0.005509</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006537</td>\n",
              "      <td>0.002988</td>\n",
              "      <td>0.004601</td>\n",
              "      <td>-0.000591</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.018465</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>0.002681</td>\n",
              "      <td>0.004024</td>\n",
              "      <td>0.006507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_80_std</th>\n",
              "      <td>-0.000008</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>-0.000012</td>\n",
              "      <td>0.002008</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>-0.002016</td>\n",
              "      <td>-0.000032</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.006972</td>\n",
              "      <td>-0.000012</td>\n",
              "      <td>-0.000044</td>\n",
              "      <td>-0.001080</td>\n",
              "      <td>0.000202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B_20_last</th>\n",
              "      <td>-0.000016</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_3_std</th>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004032</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.001020</td>\n",
              "      <td>0.002056</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>0.003008</td>\n",
              "      <td>0.000108</td>\n",
              "      <td>-0.006060</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001120</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000884</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>0.000916</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>0.001936</td>\n",
              "      <td>0.000201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D_77_sum_woe</th>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.002060</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000012</td>\n",
              "      <td>-0.000024</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>-0.000008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001004</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.000048</td>\n",
              "      <td>-0.001080</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.001104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004032</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_2_mean_m_R_5_min</th>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000032</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>-0.000044</td>\n",
              "      <td>-0.000060</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1089 rows × 46 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e650e126-97b9-4511-a199-7b144a14e062')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e650e126-97b9-4511-a199-7b144a14e062 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e650e126-97b9-4511-a199-7b144a14e062');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permu_save = premu_order.copy()"
      ],
      "metadata": {
        "id": "3LA1Ta5L6aKf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Parameter & Feature Order"
      ],
      "metadata": {
        "id": "pyV1SFNx006n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameter     = pd.DataFrame([xgb_grid[83], xgb_grid[32]], index = ['avg', 'oof'])\n",
        "\n",
        "order_avg   = [x[0] for x in orders[0]]\n",
        "weights_avg = [x[1] for x in orders[0]]\n",
        "\n",
        "order_oof   = [x[0] for x in orders[0]]\n",
        "weights_oof = [x[1] for x in orders[0]]\n",
        "\n",
        "feature_order = pd.DataFrame(list(zip(order_avg, weights_avg, order_oof, weights_oof)), columns=['order_avg', 'weights_avg', 'order_oof', 'weights_oof'])"
      ],
      "metadata": {
        "id": "bGxfvq_vRJO_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter.to_csv('/content/drive/MyDrive/KaggleAMEX/Models/freq_2/parameters.csv') \n",
        "feature_order.to_csv('/content/drive/MyDrive/KaggleAMEX/Models/freq_2/features.csv')"
      ],
      "metadata": {
        "id": "Mho5u8_SwBT_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [2-12] order_0_model_98 - 0.651396 order_0_model_94  - 0.650073"
      ],
      "metadata": {
        "id": "ySeuXKYZ0wN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameter = pd.read_csv('/content/drive/MyDrive/KaggleAMEX/Models/freq_2/parameters.csv', index_col=0)\n",
        "order     = pd.read_csv('/content/drive/MyDrive/KaggleAMEX/Models/freq_2/features.csv', index_col=0)"
      ],
      "metadata": {
        "id": "WbDAQITWzYcr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPVVjUz5Byxx"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzD_A0XoJxaT"
      },
      "source": [
        "https://towardsdatascience.com/be-careful-when-interpreting-your-features-importance-in-xgboost-6e16132588e7\n",
        "\n",
        "Gain - The relative contribution of the corresponding feature to the model. This is calculated by taking each feature’s contribution for each tree in the model. A higher value of this metric when compared to another feature implies it is more important for generating a prediction.\n",
        "\n",
        "Coverage - The relative number of observations related to this feature. For example, if you have 100 observations, 4 features and 3 trees, and suppose feature1 is used to decide the leaf node for 10, 5, and 2 observations in tree1, tree2 and tree3 respectively; then the metric will count cover for this feature as 10+5+2 = 17 observations. This will be calculated for all the 4 features and the cover will be 17 expressed as a percentage for all features’ cover metrics.\n",
        "\n",
        "Weight - The percentage representing the relative number of times a particular feature occurs in the trees of the model. In the above example, if feature1 occurred in 2 splits, 1 split and 3 splits in each of tree1, tree2 and tree3; then the weight for feature1 will be 2+1+3 = 6. The frequency for feature1 is calculated as its percentage weight over weights of all features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3ByAb_HGhUQ"
      },
      "outputs": [],
      "source": [
        "importance_types = ['cover', 'gain', 'weight', 'total_gain', 'total_cover']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipDndrnyLw3R"
      },
      "outputs": [],
      "source": [
        "df = model.get_score(importance_type='cover')\n",
        "df = pd.DataFrame.from_dict(df, orient='index', columns = ['cover'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHAbQxOOOdV3"
      },
      "outputs": [],
      "source": [
        "df = model.get_score(importance_type='gain')\n",
        "df = pd.DataFrame.from_dict(df, orient='index', columns = ['gain'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rrb7n4eJF27U",
        "0_Lz0gyTjumy",
        "juv-r73KS3a_",
        "8rX6N4YTs4-U",
        "wP8vVxNQs3CR"
      ],
      "machine_shape": "hm",
      "name": "Train/Test.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}